diff --git a/backend/Cargo.lock b/backend/Cargo.lock
index c3916e8031..25e2ff77fb 100644
--- a/backend/Cargo.lock
+++ b/backend/Cargo.lock
@@ -174,7 +174,9 @@ dependencies = [
  "assert_matches",
  "async-trait",
  "chrono",
+ "clap",
  "derive",
+ "derive-new",
  "derive_more",
  "derive_setters",
  "diesel",
@@ -189,6 +191,7 @@ dependencies = [
  "image",
  "infer",
  "infrastructure",
+ "itertools",
  "jsonwebtoken",
  "juniper",
  "juniper_rocket",
@@ -207,6 +210,7 @@ dependencies = [
  "rust_decimal_macros",
  "serde",
  "serde_json",
+ "sha2 0.10.7",
  "testcontainers",
  "testing",
  "thiserror",
diff --git a/backend/api/Cargo.toml b/backend/api/Cargo.toml
index 648c0e23c6..27ee8c6674 100644
--- a/backend/api/Cargo.toml
+++ b/backend/api/Cargo.toml
@@ -51,6 +51,9 @@ juniper = "0.15.11"
 juniper_rocket = "0.8.2"
 rocket = { version = "0.5.0-rc.2", features = ["json", "uuid"] }

+# CLI
+clap = { version = "4.1.4", features = ["derive"] }
+
 # AWS
 rusoto_core = "0.48.0"
 rusoto_s3 = "0.48.0"
@@ -74,9 +77,12 @@ chrono = "0.4"

 # Utils
 derive_more = "0.99.17"
+derive-new = "0.5.9"
 derive_setters = "0.1.5"
 dotenv = "0.15.0"
 infer = "0.12.0"
+itertools = "0.10.5"
+sha2 = "0.10.7"
 rust_decimal = { version = "1.29.1", features = ["db-diesel2-postgres"] }
 rust_decimal_macros = "1.26"
 tokio-retry = "0.3"
diff --git a/backend/api/Procfile b/backend/api/Procfile
index e363743979..505e5acd7e 100644
--- a/backend/api/Procfile
+++ b/backend/api/Procfile
@@ -2,3 +2,4 @@ web: ROCKET_PORT=$PORT ./backend/target/release/api
 events_sanity_checks: RUST_LOG=info ./backend/target/release/events_sanity_checks
 quotes_syncer: RUST_LOG=info ./backend/target/release/quotes_syncer
 hasura: ./hasura/hasura.sh
+refresh: RUST_LOG=info ./backend/target/release/refresh
diff --git a/backend/api/src/application/budget/allocate.rs b/backend/api/src/application/budget/allocate.rs
index b6739443ef..520e798aaf 100644
--- a/backend/api/src/application/budget/allocate.rs
+++ b/backend/api/src/application/budget/allocate.rs
@@ -6,14 +6,14 @@ use domain::{
 	sponsor, AggregateRepository, Amount, Budget, BudgetId, DomainError, Event, Project, ProjectId,
 	Publisher,
 };
-use infrastructure::{amqp::UniqueMessage, database::Repository};
+use infrastructure::database::Repository;
 use tracing::instrument;

 use crate::{domain::Publishable, models::Sponsor};

 #[derive(Constructor)]
 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	project_repository: AggregateRepository<Project>,
 	budget_repository: AggregateRepository<Budget>,
 	sponsor_repository: Arc<dyn Repository<Sponsor>>,
@@ -65,7 +65,6 @@ impl Usecase {
 		project
 			.map(Event::from)
 			.chain(budget.map(Event::from))
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/payment/cancel.rs b/backend/api/src/application/payment/cancel.rs
index b18af7307e..813c667519 100644
--- a/backend/api/src/application/payment/cancel.rs
+++ b/backend/api/src/application/payment/cancel.rs
@@ -3,14 +3,13 @@ use std::sync::Arc;
 use anyhow::Result;
 use derive_more::Constructor;
 use domain::{AggregateRepository, CommandId, DomainError, Event, Payment, PaymentId, Publisher};
-use infrastructure::amqp::CommandMessage;
 use tracing::instrument;

 use crate::domain::Publishable;

 #[derive(Constructor)]
 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<CommandMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	payment_repository: AggregateRepository<Payment>,
 }

@@ -25,7 +24,6 @@ impl Usecase {
 			.cancel()
 			.map_err(|e| DomainError::InvalidInputs(e.into()))?
 			.map(Event::from)
-			.map(|payload| CommandMessage::new(command_id, payload))
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/payment/invoice.rs b/backend/api/src/application/payment/invoice.rs
index 81904d7b01..b9c6fcd5f4 100644
--- a/backend/api/src/application/payment/invoice.rs
+++ b/backend/api/src/application/payment/invoice.rs
@@ -3,14 +3,13 @@ use std::sync::Arc;
 use anyhow::Result;
 use derive_more::Constructor;
 use domain::{AggregateRepository, DomainError, Event, Payment, PaymentId, Publisher};
-use infrastructure::amqp::UniqueMessage;
 use tracing::instrument;

 use crate::domain::Publishable;

 #[derive(Constructor)]
 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	payment_repository: AggregateRepository<Payment>,
 }

@@ -34,7 +33,6 @@ impl Usecase {
 		events
 			.into_iter()
 			.map(Event::from)
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
@@ -58,7 +56,6 @@ impl Usecase {
 		events
 			.into_iter()
 			.map(Event::from)
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/payment/process.rs b/backend/api/src/application/payment/process.rs
index 2b7b3fc5a6..873919c436 100644
--- a/backend/api/src/application/payment/process.rs
+++ b/backend/api/src/application/payment/process.rs
@@ -6,7 +6,6 @@ use domain::{
 	AggregateRepository, Amount, DomainError, Event, Payment, PaymentId, PaymentReceipt,
 	PaymentReceiptId, Publisher,
 };
-use infrastructure::amqp::UniqueMessage;
 use olog::IntoField;
 use tracing::instrument;

@@ -14,7 +13,7 @@ use crate::{application::dusty_bot, domain::Publishable};

 #[derive(Constructor)]
 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	payment_repository: AggregateRepository<Payment>,
 	close_issues_usecase: dusty_bot::close_issues::Usecase,
 }
@@ -36,7 +35,6 @@ impl Usecase {
 			.add_receipt(new_receipt_id, amount, receipt)
 			.map_err(|e| DomainError::InvalidInputs(e.into()))?
 			.map(Event::from)
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/payment/request.rs b/backend/api/src/application/payment/request.rs
index f6bc261acc..15fb518be5 100644
--- a/backend/api/src/application/payment/request.rs
+++ b/backend/api/src/application/payment/request.rs
@@ -8,7 +8,6 @@ use domain::{
 	Payment, PaymentId, PaymentReason, PaymentWorkItem, Project, ProjectId, Publisher, UserId,
 };
 use futures::future::try_join_all;
-use infrastructure::amqp::CommandMessage;
 use rust_decimal::Decimal;
 use tracing::instrument;

@@ -16,7 +15,7 @@ use crate::domain::{services::indexer, Publishable};

 #[derive(Constructor)]
 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<CommandMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	project_repository: AggregateRepository<Project>,
 	budget_repository: AggregateRepository<Budget>,
 	github_indexer_service: Arc<dyn indexer::Service>,
@@ -93,7 +92,6 @@ impl Usecase {
 		budget
 			.map(Event::from)
 			.chain(payment.map(Event::from))
-			.map(|payload| CommandMessage::new(command_id, payload))
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/project/accept_leader_invitation.rs b/backend/api/src/application/project/accept_leader_invitation.rs
index 8392df6f89..514dd796d8 100644
--- a/backend/api/src/application/project/accept_leader_invitation.rs
+++ b/backend/api/src/application/project/accept_leader_invitation.rs
@@ -2,20 +2,20 @@ use std::sync::Arc;

 use anyhow::{anyhow, Result};
 use domain::{AggregateRepository, DomainError, Event, GithubUserId, Project, Publisher, UserId};
-use infrastructure::{amqp::UniqueMessage, database::ImmutableRepository};
+use infrastructure::database::ImmutableRepository;
 use tracing::instrument;

 use crate::{domain::Publishable, models::*};

 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	invitations_repository: Arc<dyn ImmutableRepository<PendingProjectLeaderInvitation>>,
 	project_repository: AggregateRepository<Project>,
 }

 impl Usecase {
 	pub fn new(
-		event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+		event_publisher: Arc<dyn Publisher<Event>>,
 		invitations_repository: Arc<dyn ImmutableRepository<PendingProjectLeaderInvitation>>,
 		project_repository: AggregateRepository<Project>,
 	) -> Self {
@@ -46,7 +46,6 @@ impl Usecase {
 			.assign_leader(user_id)
 			.map_err(|e| DomainError::InvalidInputs(e.into()))?
 			.map(Event::from)
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/project/apply.rs b/backend/api/src/application/project/apply.rs
index bdb1291015..34fd923358 100644
--- a/backend/api/src/application/project/apply.rs
+++ b/backend/api/src/application/project/apply.rs
@@ -6,7 +6,6 @@ use domain::{
 	AggregateRepository, Application, ApplicationId, DomainError, Event, Project, ProjectId,
 	Publisher, UserId,
 };
-use infrastructure::amqp::UniqueMessage;
 use tracing::instrument;
 use uuid::Uuid;

@@ -15,7 +14,7 @@ use crate::domain::Publishable;
 #[derive(Constructor)]
 pub struct Usecase {
 	project_repository: AggregateRepository<Project>,
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 }

 impl Usecase {
@@ -33,7 +32,6 @@ impl Usecase {
 			.map_err(|e| DomainError::InternalError(e.into()))?
 			.map(Event::from)
 			.chain(Application::create(application_id, project_id, applicant_id).map(Event::from))
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/project/create.rs b/backend/api/src/application/project/create.rs
index b42649cb35..a3edde6631 100644
--- a/backend/api/src/application/project/create.rs
+++ b/backend/api/src/application/project/create.rs
@@ -5,7 +5,7 @@ use derive_more::Constructor;
 use domain::{
 	sponsor, Amount, BudgetId, DomainError, Event, Project, ProjectId, ProjectVisibility, Publisher,
 };
-use infrastructure::{amqp::UniqueMessage, database::Repository};
+use infrastructure::database::Repository;
 use reqwest::Url;
 use tracing::instrument;

@@ -18,7 +18,7 @@ use crate::{

 #[derive(Constructor)]
 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	project_details_repository: Arc<dyn Repository<ProjectDetails>>,
 	image_store: Arc<dyn ImageStoreService>,
 	budget_allocation_usecase: application::budget::allocate::Usecase,
@@ -77,7 +77,6 @@ impl Usecase {
 		project
 			.map(Event::from)
 			.chain(budget.unwrap_or_default().map(Event::from))
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/project/link_github_repo.rs b/backend/api/src/application/project/link_github_repo.rs
index 8d0de01c14..b0ec3ca4e4 100644
--- a/backend/api/src/application/project/link_github_repo.rs
+++ b/backend/api/src/application/project/link_github_repo.rs
@@ -4,20 +4,19 @@ use anyhow::{anyhow, Result};
 use domain::{
 	AggregateRepository, DomainError, Event, GithubRepoId, Project, ProjectId, Publisher,
 };
-use infrastructure::amqp::UniqueMessage;
 use tracing::instrument;

 use crate::domain::{GithubRepoExists, Publishable};

 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	project_repository: AggregateRepository<Project>,
 	github_repo_exists: Arc<dyn GithubRepoExists>,
 }

 impl Usecase {
 	pub fn new(
-		event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+		event_publisher: Arc<dyn Publisher<Event>>,
 		project_repository: AggregateRepository<Project>,
 		github_repo_exists: Arc<dyn GithubRepoExists>,
 	) -> Self {
@@ -52,7 +51,6 @@ impl Usecase {
 			.link_github_repo(github_repo_id)
 			.map_err(|e| DomainError::InvalidInputs(e.into()))?
 			.map(Event::from)
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/api/src/application/project/remove_leader.rs b/backend/api/src/application/project/remove_leader.rs
index c1a98ed911..f024a31bc6 100644
--- a/backend/api/src/application/project/remove_leader.rs
+++ b/backend/api/src/application/project/remove_leader.rs
@@ -1,20 +1,18 @@
 use std::sync::Arc;

-use domain::{
-	AggregateRepository, Destination, DomainError, Event, Project, ProjectId, Publisher, UserId,
-};
-use event_store::bus::QUEUE_NAME as EVENT_STORE_QUEUE;
-use infrastructure::amqp::UniqueMessage;
+use domain::{AggregateRepository, DomainError, Event, Project, ProjectId, Publisher, UserId};
 use tracing::instrument;

+use crate::domain::Publishable;
+
 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	project_repository: AggregateRepository<Project>,
 }

 impl Usecase {
 	pub fn new(
-		event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+		event_publisher: Arc<dyn Publisher<Event>>,
 		project_repository: AggregateRepository<Project>,
 	) -> Self {
 		Self {
@@ -31,15 +29,12 @@ impl Usecase {
 	) -> Result<(), DomainError> {
 		let project = self.project_repository.find_by_id(project_id)?;

-		let events = project
+		project
 			.unassign_leader(*user_id)
 			.map_err(|e| DomainError::InvalidInputs(e.into()))?
 			.map(Event::from)
-			.map(UniqueMessage::new)
-			.collect::<Vec<_>>();
-
-		self.event_publisher
-			.publish_many(Destination::queue(EVENT_STORE_QUEUE), &events)
+			.collect::<Vec<_>>()
+			.publish(self.event_publisher.clone())
 			.await?;

 		Ok(())
diff --git a/backend/api/src/application/project/unlink_github_repo.rs b/backend/api/src/application/project/unlink_github_repo.rs
index dc4d02035e..5fe6da454e 100644
--- a/backend/api/src/application/project/unlink_github_repo.rs
+++ b/backend/api/src/application/project/unlink_github_repo.rs
@@ -4,19 +4,18 @@ use anyhow::Result;
 use domain::{
 	AggregateRepository, DomainError, Event, GithubRepoId, Project, ProjectId, Publisher,
 };
-use infrastructure::amqp::UniqueMessage;
 use tracing::instrument;

 use crate::domain::Publishable;

 pub struct Usecase {
-	event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_publisher: Arc<dyn Publisher<Event>>,
 	project_repository: AggregateRepository<Project>,
 }

 impl Usecase {
 	pub fn new(
-		event_publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+		event_publisher: Arc<dyn Publisher<Event>>,
 		project_repository: AggregateRepository<Project>,
 	) -> Self {
 		Self {
@@ -38,7 +37,6 @@ impl Usecase {
 			.unlink_github_repo(github_repo_id)
 			.map_err(|e| DomainError::InvalidInputs(e.into()))?
 			.map(Event::from)
-			.map(UniqueMessage::new)
 			.collect::<Vec<_>>()
 			.publish(self.event_publisher.clone())
 			.await?;
diff --git a/backend/event-listeners/src/bin/refresh/app.yaml b/backend/api/src/bin/refresh/app.yaml
similarity index 100%
rename from backend/event-listeners/src/bin/refresh/app.yaml
rename to backend/api/src/bin/refresh/app.yaml
diff --git a/backend/api/src/bin/refresh/cli.rs b/backend/api/src/bin/refresh/cli.rs
new file mode 100644
index 0000000000..0bef968cd2
--- /dev/null
+++ b/backend/api/src/bin/refresh/cli.rs
@@ -0,0 +1,20 @@
+use clap::{ArgGroup, Parser};
+
+/// Refresh any aggregate
+#[derive(Parser, Debug)]
+#[command(author, about, long_about)]
+#[command(group(ArgGroup::new("ids").required(true).args(["id", "all"]),
+))]
+pub struct Args {
+	/// Name of the aggregate
+	#[arg(short, long)]
+	pub name: String,
+
+	/// Aggregate ID
+	#[arg(short, long)]
+	pub id: Vec<String>,
+
+	/// Aggregate ID
+	#[arg(short, long)]
+	pub all: bool,
+}
diff --git a/backend/event-listeners/src/bin/refresh/main.rs b/backend/api/src/bin/refresh/main.rs
similarity index 63%
rename from backend/event-listeners/src/bin/refresh/main.rs
rename to backend/api/src/bin/refresh/main.rs
index e703099283..bf39cbf597 100644
--- a/backend/event-listeners/src/bin/refresh/main.rs
+++ b/backend/api/src/bin/refresh/main.rs
@@ -2,9 +2,10 @@ use std::sync::Arc;

 use ::infrastructure::config;
 use anyhow::{anyhow, Result};
+use api::Config;
 use clap::Parser;
+use domain::{Application, Budget, Payment, Project};
 use dotenv::dotenv;
-use event_listeners::Config;
 use futures::future::try_join_all;
 use infrastructure::{database, tracing::Tracer};

@@ -22,12 +23,16 @@ async fn main() -> Result<()> {

 	let mut registry = Registry::new();

-	refresher::application::create(database.clone()).register(&mut registry, "Application")?;
-	refresher::budget::create(database.clone()).register(&mut registry, "Budget")?;
-	refresher::project::create(database.clone()).register(&mut registry, "Project")?;
-	refresher::payment::create(database.clone()).register(&mut registry, "Payment")?;
+	refresher::create::<Application>(database.clone()).register(&mut registry, "Application")?;
+	refresher::create::<Budget>(database.clone()).register(&mut registry, "Budget")?;
+	refresher::create::<Project>(database.clone()).register(&mut registry, "Project")?;
+	refresher::create::<Payment>(database.clone()).register(&mut registry, "Payment")?;

-	let (aggregate_name, aggregate_ids, all_ids) = cli::Args::parse().dissolve();
+	let cli::Args {
+		name: aggregate_name,
+		id: aggregate_ids,
+		all: all_ids,
+	} = cli::Args::parse();

 	let refresher = registry.get(&aggregate_name).ok_or_else(|| anyhow!("Aggregate not found"))?;

diff --git a/backend/api/src/bin/refresh/refresher/mod.rs b/backend/api/src/bin/refresh/refresher/mod.rs
new file mode 100644
index 0000000000..94c88f04ca
--- /dev/null
+++ b/backend/api/src/bin/refresh/refresher/mod.rs
@@ -0,0 +1,88 @@
+use std::{str::FromStr, sync::Arc};
+
+use anyhow::{anyhow, Result};
+use api::domain::projectors::projections;
+use async_trait::async_trait;
+use derive_more::Constructor;
+use domain::{Event, EventListener, EventSourcable, EventStore, Identified};
+use infrastructure::{database, event_store::Named};
+use itertools::Itertools;
+use olog::info;
+pub use registry::{Registrable, Registry};
+
+mod registry;
+
+#[derive(Constructor)]
+pub struct Refresher<A: EventSourcable> {
+	event_store: Arc<dyn EventStore<A>>,
+	projector: Arc<dyn EventListener<Event>>,
+}
+
+#[async_trait]
+pub trait Refreshable {
+	fn all_ids(&self) -> Result<Vec<String>>;
+	async fn refresh(&self, id: &str) -> Result<()>;
+}
+
+#[async_trait]
+impl<A: EventSourcable> Refreshable for Refresher<A>
+where
+	Event: From<A::Event>,
+	A::Id: FromStr,
+{
+	fn all_ids(&self) -> Result<Vec<String>> {
+		let ids = self
+			.event_store
+			.list()
+			.map_err(|_| anyhow!("Could not list event ids from store"))?
+			.into_iter()
+			.map(|e| e.id().to_string())
+			.unique()
+			.collect();
+
+		Ok(ids)
+	}
+
+	async fn refresh(&self, id: &str) -> Result<()> {
+		info!(
+			"Refreshing {} {id}",
+			std::any::type_name::<A>().split(':').last().unwrap_or_default()
+		);
+		let id = A::Id::from_str(id).map_err(|_| anyhow!("Unable to parse aggregate id"))?;
+		let events = self.event_store.list_by_id(&id)?;
+
+		if events.is_empty() {
+			return Err(anyhow!("No event found"));
+		}
+
+		for event in events {
+			self.projector.on_event(event.into()).await?;
+		}
+		Ok(())
+	}
+}
+
+pub fn create<A: EventSourcable + Named>(database: Arc<database::Client>) -> impl Refreshable
+where
+	Event: From<A::Event>,
+	A::Id: FromStr,
+{
+	let projector = projections::Projector::new(
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+		database.clone(),
+	);
+
+	Refresher::<A>::new(database, Arc::new(projector))
+}
diff --git a/backend/event-listeners/src/bin/refresh/refresher/registry.rs b/backend/api/src/bin/refresh/refresher/registry.rs
similarity index 100%
rename from backend/event-listeners/src/bin/refresh/refresher/registry.rs
rename to backend/api/src/bin/refresh/refresher/registry.rs
diff --git a/backend/api/src/domain/mod.rs b/backend/api/src/domain/mod.rs
index 98ed4a6ee6..569b589b23 100644
--- a/backend/api/src/domain/mod.rs
+++ b/backend/api/src/domain/mod.rs
@@ -4,6 +4,8 @@ pub use publishable::Publishable;
 pub mod permissions;
 pub use permissions::Permissions;

+pub mod projectors;
+
 mod specifications;
 #[cfg(test)]
 pub use specifications::MockGithubRepoExists;
diff --git a/backend/api/src/domain/projectors/event_store.rs b/backend/api/src/domain/projectors/event_store.rs
new file mode 100644
index 0000000000..0fbd150a19
--- /dev/null
+++ b/backend/api/src/domain/projectors/event_store.rs
@@ -0,0 +1,21 @@
+use std::sync::Arc;
+
+use derive_more::Constructor;
+use domain::{Event, EventListener, SubscriberCallbackError};
+
+use crate::models::EventRepository;
+
+#[derive(Constructor)]
+pub struct Projector {
+	events_repository: Arc<dyn EventRepository>,
+}
+
+#[async_trait]
+impl EventListener<Event> for Projector {
+	async fn on_event(&self, event: Event) -> Result<(), SubscriberCallbackError> {
+		self.events_repository
+			.append(event.try_into().map_err(SubscriberCallbackError::Fatal)?)
+			.map_err(|e| SubscriberCallbackError::Fatal(e.into()))?;
+		Ok(())
+	}
+}
diff --git a/backend/api/src/domain/projectors/mod.rs b/backend/api/src/domain/projectors/mod.rs
new file mode 100644
index 0000000000..7a67e0e7e9
--- /dev/null
+++ b/backend/api/src/domain/projectors/mod.rs
@@ -0,0 +1,2 @@
+pub mod event_store;
+pub mod projections;
diff --git a/backend/api/src/domain/projectors/projections.rs b/backend/api/src/domain/projectors/projections.rs
new file mode 100644
index 0000000000..4344fb4b89
--- /dev/null
+++ b/backend/api/src/domain/projectors/projections.rs
@@ -0,0 +1,223 @@
+use std::{convert::TryFrom, sync::Arc};
+
+use anyhow::Result;
+use async_trait::async_trait;
+use derive_new::new;
+use domain::{
+	ApplicationEvent, BudgetEvent, Event, EventListener, PaymentEvent, PaymentWorkItem,
+	ProjectEvent, SubscriberCallbackError,
+};
+use infrastructure::database::{ImmutableRepository, Repository};
+use rust_decimal::Decimal;
+use tracing::instrument;
+
+use crate::models::*;
+
+#[allow(clippy::too_many_arguments)]
+#[derive(new)]
+pub struct Projector {
+	project_repository: Arc<dyn ImmutableRepository<Project>>,
+	project_lead_repository: Arc<dyn ImmutableRepository<ProjectLead>>,
+	project_github_repos_repository: Arc<dyn ImmutableRepository<ProjectGithubRepo>>,
+	projects_contributors_repository: Arc<dyn ProjectsContributorRepository>,
+	projects_pending_contributors_repository: Arc<dyn ProjectsPendingContributorRepository>,
+	project_budgets_repository: Arc<dyn ImmutableRepository<ProjectsBudget>>,
+	applications_repository: Arc<dyn Repository<Application>>,
+	budget_repository: Arc<dyn Repository<Budget>>,
+	payment_request_repository: Arc<dyn Repository<PaymentRequest>>,
+	payment_repository: Arc<dyn Repository<Payment>>,
+	work_item_repository: Arc<dyn WorkItemRepository>,
+	projects_rewarded_users_repository: Arc<dyn ProjectsRewardedUserRepository>,
+	// TODO: replace the repositories below by API call to indexer in another projector
+	github_repo_index_repository: Arc<dyn GithubRepoIndexRepository>,
+	github_user_index_repository: Arc<dyn GithubUserIndexRepository>,
+}
+
+#[async_trait]
+impl EventListener<Event> for Projector {
+	#[instrument(name = "project_projection", skip(self))]
+	async fn on_event(&self, event: Event) -> Result<(), SubscriberCallbackError> {
+		match event {
+			Event::Application(event) => match event {
+				ApplicationEvent::Received {
+					id,
+					project_id,
+					applicant_id,
+					received_at,
+				} => {
+					self.applications_repository.try_insert(Application {
+						id,
+						received_at,
+						project_id,
+						applicant_id,
+					})?;
+				},
+			},
+			Event::Budget(event) => match event {
+				BudgetEvent::Created { id, currency } => {
+					self.budget_repository.upsert(Budget {
+						id,
+						initial_amount: Decimal::ZERO,
+						remaining_amount: Decimal::ZERO,
+						currency: currency.try_into()?,
+					})?;
+				},
+				BudgetEvent::Allocated { id, amount, .. } => {
+					let mut budget = self.budget_repository.find_by_id(id)?;
+					budget.remaining_amount += amount;
+					budget.initial_amount += amount;
+					self.budget_repository.update(budget)?;
+				},
+				BudgetEvent::Spent { id, amount } => {
+					let mut budget = self.budget_repository.find_by_id(id)?;
+					budget.remaining_amount -= amount;
+					self.budget_repository.update(budget)?;
+				},
+			},
+			Event::Payment(event) => match event {
+				PaymentEvent::Requested {
+					id: payment_id,
+					project_id,
+					requestor_id,
+					recipient_id,
+					amount,
+					reason,
+					duration_worked,
+					requested_at,
+				} => {
+					self.payment_request_repository.upsert(PaymentRequest {
+						id: payment_id,
+						project_id,
+						requestor_id,
+						recipient_id,
+						amount: *amount.amount(),
+						currency: amount.currency().try_into()?,
+						requested_at,
+						invoice_received_at: None,
+						hours_worked: i32::try_from(duration_worked.num_hours()).unwrap_or(0),
+					})?;
+
+					reason.work_items.into_iter().try_for_each(
+						|work_item| -> Result<(), SubscriberCallbackError> {
+							let repo_id = match work_item {
+								PaymentWorkItem::Issue { repo_id, .. }
+								| PaymentWorkItem::CodeReview { repo_id, .. }
+								| PaymentWorkItem::PullRequest { repo_id, .. } => repo_id,
+							};
+
+							self.work_item_repository.try_insert(
+								(project_id, payment_id, recipient_id, work_item).into(),
+							)?;
+
+							self.github_repo_index_repository.start_indexing(repo_id)?;
+							Ok(())
+						},
+					)?;
+
+					self.github_user_index_repository.try_insert(GithubUserIndex {
+						user_id: recipient_id,
+						..Default::default()
+					})?;
+
+					self.projects_rewarded_users_repository
+						.increase_user_reward_count_for_project(&project_id, &recipient_id)?;
+				},
+				PaymentEvent::Cancelled { id: payment_id } => {
+					let payment_request = self.payment_request_repository.find_by_id(payment_id)?;
+					self.payment_request_repository.delete(payment_id)?;
+					self.work_item_repository.delete_by_payment_id(payment_id)?;
+
+					self.projects_rewarded_users_repository
+						.decrease_user_reward_count_for_project(
+							&payment_request.project_id,
+							&payment_request.recipient_id,
+						)?;
+				},
+				PaymentEvent::Processed {
+					id: payment_id,
+					receipt_id,
+					amount,
+					receipt,
+					processed_at,
+				} => {
+					self.payment_repository.upsert(Payment {
+						id: receipt_id,
+						amount: *amount.amount(),
+						currency_code: amount.currency().to_string(),
+						receipt: serde_json::to_value(receipt)
+							.map_err(|e| SubscriberCallbackError::Discard(e.into()))?,
+						request_id: payment_id,
+						processed_at,
+					})?;
+				},
+				PaymentEvent::InvoiceReceived {
+					id: payment_id,
+					received_at,
+				} => {
+					let mut payment_request =
+						self.payment_request_repository.find_by_id(payment_id)?;
+					payment_request.invoice_received_at = Some(received_at);
+					self.payment_request_repository.update(payment_request)?;
+				},
+				PaymentEvent::InvoiceRejected { id: payment_id } => {
+					let mut payment_request =
+						self.payment_request_repository.find_by_id(payment_id)?;
+					payment_request.invoice_received_at = None;
+					self.payment_request_repository.update(payment_request)?;
+				},
+			},
+			Event::Project(event) => match event {
+				ProjectEvent::Created { id } => {
+					self.project_repository.try_insert(Project { id })?;
+				},
+				ProjectEvent::LeaderAssigned {
+					id: project_id,
+					leader_id,
+					assigned_at,
+				} => {
+					self.project_lead_repository.try_insert(ProjectLead {
+						project_id,
+						user_id: leader_id,
+						assigned_at,
+					})?;
+				},
+				ProjectEvent::LeaderUnassigned { id, leader_id } => {
+					self.project_lead_repository.delete((id, leader_id))?;
+				},
+				ProjectEvent::BudgetLinked { id, budget_id, .. } => {
+					self.project_budgets_repository.try_insert(ProjectsBudget {
+						project_id: id,
+						budget_id,
+					})?;
+				},
+				ProjectEvent::GithubRepoLinked {
+					id: project_id,
+					github_repo_id,
+				} => {
+					self.project_github_repos_repository.try_insert(ProjectGithubRepo {
+						project_id,
+						github_repo_id,
+					})?;
+					self.github_repo_index_repository.start_indexing(github_repo_id)?;
+					self.projects_contributors_repository
+						.refresh_project_contributor_list(&project_id)?;
+					self.projects_pending_contributors_repository
+						.refresh_project_pending_contributor_list(&project_id)?;
+				},
+				ProjectEvent::GithubRepoUnlinked {
+					id: project_id,
+					github_repo_id,
+				} => {
+					self.project_github_repos_repository.delete((project_id, github_repo_id))?;
+					self.projects_contributors_repository
+						.refresh_project_contributor_list(&project_id)?;
+					self.projects_pending_contributors_repository
+						.refresh_project_pending_contributor_list(&project_id)?;
+				},
+				ProjectEvent::Applied { .. } => (),
+			},
+		}
+
+		Ok(())
+	}
+}
diff --git a/backend/api/src/domain/publishable.rs b/backend/api/src/domain/publishable.rs
index a61bd60418..fb54fce215 100644
--- a/backend/api/src/domain/publishable.rs
+++ b/backend/api/src/domain/publishable.rs
@@ -1,7 +1,6 @@
 use std::sync::Arc;

-use domain::{Destination, Message, Publisher, PublisherError};
-use event_store::bus::QUEUE_NAME as EVENT_STORE_QUEUE;
+use domain::{Message, Publisher, PublisherError};

 #[async_trait]
 pub trait Publishable<M: Message> {
@@ -11,7 +10,7 @@ pub trait Publishable<M: Message> {
 #[async_trait]
 impl<M: Message + Sync + Send> Publishable<M> for Vec<M> {
 	async fn publish(&self, publisher: Arc<dyn Publisher<M>>) -> Result<(), PublisherError> {
-		publisher.publish_many(Destination::queue(EVENT_STORE_QUEUE), self).await?;
+		publisher.publish_many(self).await?;
 		Ok(())
 	}
 }
diff --git a/backend/event-listeners/src/models/applications.rs b/backend/api/src/models/applications.rs
similarity index 100%
rename from backend/event-listeners/src/models/applications.rs
rename to backend/api/src/models/applications.rs
diff --git a/backend/event-listeners/src/models/budgets.rs b/backend/api/src/models/budgets.rs
similarity index 94%
rename from backend/event-listeners/src/models/budgets.rs
rename to backend/api/src/models/budgets.rs
index f5c6c88f01..d0f0a6097f 100644
--- a/backend/event-listeners/src/models/budgets.rs
+++ b/backend/api/src/models/budgets.rs
@@ -3,7 +3,7 @@ use domain::BudgetId;
 use infrastructure::database::{enums::Currency, schema::budgets};
 use rust_decimal::Decimal;

-#[derive(Debug, Insertable, Identifiable, Queryable, AsChangeset, Model)]
+#[derive(Debug, Insertable, Identifiable, Queryable, AsChangeset, Model, PartialEq, Eq)]
 pub struct Budget {
 	pub id: BudgetId,
 	pub initial_amount: Decimal,
diff --git a/backend/api/src/models/crypto_usd_quotes copy.rs b/backend/api/src/models/crypto_usd_quotes copy.rs
new file mode 100644
index 0000000000..ec505fcbe3
--- /dev/null
+++ b/backend/api/src/models/crypto_usd_quotes copy.rs
@@ -0,0 +1,33 @@
+use chrono::{NaiveDateTime, Utc};
+use diesel::{Identifiable, Queryable};
+use infrastructure::database::{enums::Currency, schema::crypto_usd_quotes};
+use rust_decimal::Decimal;
+use serde::{Deserialize, Serialize};
+
+#[derive(
+	Debug, Clone, Insertable, Identifiable, Serialize, Deserialize, AsChangeset, Queryable, Model,
+)]
+#[diesel(primary_key(currency))]
+pub struct CryptoUsdQuote {
+	pub currency: Currency,
+	pub price: Decimal,
+	pub updated_at: NaiveDateTime,
+}
+
+impl CryptoUsdQuote {
+	pub fn new(currency: Currency, price: Decimal) -> Self {
+		Self {
+			currency,
+			price,
+			updated_at: Utc::now().naive_utc(),
+		}
+	}
+}
+
+impl Identifiable for CryptoUsdQuote {
+	type Id = Currency;
+
+	fn id(self) -> Self::Id {
+		self.currency
+	}
+}
diff --git a/backend/api/src/models/events/mod.rs b/backend/api/src/models/events/mod.rs
new file mode 100644
index 0000000000..d701f6abde
--- /dev/null
+++ b/backend/api/src/models/events/mod.rs
@@ -0,0 +1,62 @@
+use chrono::{NaiveDateTime, Utc};
+use diesel::Insertable;
+use domain::{CommandId, Identified};
+use infrastructure::database::schema::events;
+use serde::{Deserialize, Serialize};
+use serde_json::{to_value as to_json, Value as Json};
+
+mod repository;
+pub use repository::Repository;
+
+#[derive(Debug, Clone, Insertable, Serialize, Deserialize, Queryable, PartialEq, Eq)]
+pub struct Event {
+	pub timestamp: NaiveDateTime,
+	pub aggregate_name: String,
+	pub aggregate_id: String,
+	pub payload: Json,
+	pub metadata: Json,
+	pub command_id: Option<CommandId>,
+}
+
+impl TryFrom<domain::Event> for Event {
+	type Error = anyhow::Error;
+
+	fn try_from(event: domain::Event) -> Result<Self, Self::Error> {
+		Ok(Self {
+			timestamp: Utc::now().naive_utc(),
+			aggregate_id: aggregate_id(&event),
+			aggregate_name: aggregate_name(&event),
+			payload: serialize_event(&event)?,
+			metadata: Default::default(),
+			command_id: None,
+		})
+	}
+}
+
+fn serialize_event(event: &domain::Event) -> Result<Json, serde_json::Error> {
+	match event {
+		domain::Event::Application(event) => to_json(event),
+		domain::Event::Budget(event) => to_json(event),
+		domain::Event::Payment(event) => to_json(event),
+		domain::Event::Project(event) => to_json(event),
+	}
+}
+
+fn aggregate_name(event: &domain::Event) -> String {
+	match event {
+		domain::Event::Application(_) => "APPLICATION",
+		domain::Event::Budget(_) => "BUDGET",
+		domain::Event::Payment(_) => "PAYMENT",
+		domain::Event::Project(_) => "PROJECT",
+	}
+	.to_string()
+}
+
+fn aggregate_id(event: &domain::Event) -> String {
+	match event {
+		domain::Event::Application(event) => event.id().to_string(),
+		domain::Event::Budget(event) => event.id().to_string(),
+		domain::Event::Payment(event) => event.id().to_string(),
+		domain::Event::Project(event) => event.id().to_string(),
+	}
+}
diff --git a/backend/api/src/models/events/repository.rs b/backend/api/src/models/events/repository.rs
new file mode 100644
index 0000000000..9e8a74b51e
--- /dev/null
+++ b/backend/api/src/models/events/repository.rs
@@ -0,0 +1,16 @@
+use diesel::RunQueryDsl;
+use infrastructure::database::{self, schema::events, DatabaseError};
+
+use super::Event;
+
+pub trait Repository: Send + Sync {
+	fn append(&self, event: Event) -> Result<(), DatabaseError>;
+}
+
+impl Repository for database::Client {
+	fn append(&self, event: Event) -> Result<(), DatabaseError> {
+		let mut connection = self.connection()?;
+		diesel::insert_into(events::table).values(&event).execute(&mut *connection)?;
+		Ok(())
+	}
+}
diff --git a/backend/api/src/models/github_issues/mod.rs b/backend/api/src/models/github_issues/mod.rs
new file mode 100644
index 0000000000..7cad3b01fa
--- /dev/null
+++ b/backend/api/src/models/github_issues/mod.rs
@@ -0,0 +1,49 @@
+use chrono::NaiveDateTime;
+use diesel::Identifiable;
+use diesel_json::Json;
+use domain::{GithubIssueId, GithubIssueNumber, GithubRepoId, GithubUserId};
+use infrastructure::database::{enums::GithubIssueStatus, schema::github_issues};
+use serde::{Deserialize, Serialize};
+
+#[derive(
+	Debug, Clone, Insertable, AsChangeset, Identifiable, Queryable, Serialize, Deserialize, Model,
+)]
+pub struct GithubIssue {
+	pub id: GithubIssueId,
+	pub repo_id: GithubRepoId,
+	pub number: GithubIssueNumber,
+	pub created_at: NaiveDateTime,
+	pub author_id: GithubUserId,
+	pub status: GithubIssueStatus,
+	pub title: String,
+	pub html_url: String,
+	pub closed_at: Option<NaiveDateTime>,
+	pub assignee_ids: Json<Vec<GithubUserId>>,
+	pub comments_count: i64,
+}
+
+impl Identifiable for GithubIssue {
+	type Id = GithubIssueId;
+
+	fn id(self) -> Self::Id {
+		self.id
+	}
+}
+
+impl From<domain::GithubIssue> for GithubIssue {
+	fn from(issue: domain::GithubIssue) -> Self {
+		GithubIssue {
+			id: issue.id,
+			repo_id: issue.repo_id,
+			number: issue.number,
+			created_at: issue.created_at.naive_utc(),
+			author_id: issue.author.id,
+			status: issue.status.into(),
+			title: issue.title,
+			html_url: issue.html_url.to_string(),
+			closed_at: issue.closed_at.map(|date| date.naive_utc()),
+			assignee_ids: Json::new(issue.assignees.iter().map(|assignee| assignee.id).collect()),
+			comments_count: issue.comments_count as i64,
+		}
+	}
+}
diff --git a/backend/api/src/models/github_pull_request_indexes/mod.rs b/backend/api/src/models/github_pull_request_indexes/mod.rs
new file mode 100644
index 0000000000..b43a885b95
--- /dev/null
+++ b/backend/api/src/models/github_pull_request_indexes/mod.rs
@@ -0,0 +1,43 @@
+mod repository;
+
+use diesel::Identifiable;
+use domain::GithubPullRequestId;
+use infrastructure::database::schema::github_pull_request_indexes;
+pub use repository::Repository;
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+
+#[derive(
+	Debug,
+	Default,
+	Clone,
+	Insertable,
+	AsChangeset,
+	Identifiable,
+	Queryable,
+	Serialize,
+	Deserialize,
+	Model,
+)]
+#[diesel(table_name = github_pull_request_indexes, primary_key(pull_request_id))]
+pub struct GithubPullRequestIndex {
+	pub pull_request_id: GithubPullRequestId,
+	pub pull_request_indexer_state: Option<Value>,
+}
+
+impl GithubPullRequestIndex {
+	pub fn new(pull_request_id: GithubPullRequestId) -> Self {
+		Self {
+			pull_request_id,
+			..Default::default()
+		}
+	}
+}
+
+impl Identifiable for GithubPullRequestIndex {
+	type Id = GithubPullRequestId;
+
+	fn id(self) -> Self::Id {
+		self.pull_request_id
+	}
+}
diff --git a/backend/api/src/models/github_pull_request_indexes/repository.rs b/backend/api/src/models/github_pull_request_indexes/repository.rs
new file mode 100644
index 0000000000..e0ffbfad14
--- /dev/null
+++ b/backend/api/src/models/github_pull_request_indexes/repository.rs
@@ -0,0 +1,59 @@
+use diesel::{ExpressionMethods, QueryDsl, RunQueryDsl};
+use domain::GithubPullRequestId;
+use infrastructure::{
+	contextualized_error::IntoContextualizedError,
+	database,
+	database::{schema::github_pull_request_indexes::dsl, Result},
+};
+
+use super::GithubPullRequestIndex;
+
+pub trait Repository: database::Repository<GithubPullRequestIndex> {
+	fn select_pull_request_indexer_state(
+		&self,
+		pull_request_id: &GithubPullRequestId,
+	) -> Result<Option<serde_json::Value>>;
+	fn upsert_pull_request_indexer_state(
+		&self,
+		pull_request_id: &GithubPullRequestId,
+		state: serde_json::Value,
+	) -> Result<()>;
+}
+
+impl Repository for database::Client {
+	fn select_pull_request_indexer_state(
+		&self,
+		pull_request_id: &GithubPullRequestId,
+	) -> Result<Option<serde_json::Value>> {
+		let mut connection = self.connection()?;
+		let state = dsl::github_pull_request_indexes
+			.select(dsl::pull_request_indexer_state)
+			.filter(dsl::pull_request_id.eq(pull_request_id))
+			.first(&mut *connection)
+			.err_with_context(format!(
+				"select pull_request_indexer_state from github_pull_request_indexes where id={pull_request_id}"
+			))?;
+		Ok(state)
+	}
+
+	fn upsert_pull_request_indexer_state(
+		&self,
+		pull_request_id: &GithubPullRequestId,
+		state: serde_json::Value,
+	) -> Result<()> {
+		let mut connection = self.connection()?;
+		diesel::insert_into(dsl::github_pull_request_indexes)
+			.values((
+				dsl::pull_request_id.eq(pull_request_id),
+				dsl::pull_request_indexer_state.eq(&state),
+			))
+			.on_conflict(dsl::pull_request_id)
+			.do_update()
+			.set(dsl::pull_request_indexer_state.eq(&state))
+			.execute(&mut *connection)
+			.err_with_context(format!(
+				"update github_pull_request_indexes set github_pull_request_indexes where id={pull_request_id}"
+			))?;
+		Ok(())
+	}
+}
diff --git a/backend/api/src/models/github_pull_requests/closing_issues.rs b/backend/api/src/models/github_pull_requests/closing_issues.rs
new file mode 100644
index 0000000000..394cb4c77d
--- /dev/null
+++ b/backend/api/src/models/github_pull_requests/closing_issues.rs
@@ -0,0 +1,29 @@
+use diesel::Identifiable;
+use domain::{GithubIssueId, GithubPullRequestId};
+use infrastructure::database::schema::closing_issues;
+use serde::{Deserialize, Serialize};
+
+#[derive(
+	Debug,
+	Clone,
+	Insertable,
+	Identifiable,
+	Queryable,
+	Serialize,
+	Deserialize,
+	ImmutableModel,
+	PartialEq,
+)]
+#[diesel(primary_key(github_issue_id, github_pull_request_id))]
+pub struct ClosingIssue {
+	pub github_issue_id: GithubIssueId,
+	pub github_pull_request_id: GithubPullRequestId,
+}
+
+impl Identifiable for ClosingIssue {
+	type Id = (GithubIssueId, GithubPullRequestId);
+
+	fn id(self) -> Self::Id {
+		(self.github_issue_id, self.github_pull_request_id)
+	}
+}
diff --git a/backend/api/src/models/github_pull_requests/commit.rs b/backend/api/src/models/github_pull_requests/commit.rs
new file mode 100644
index 0000000000..93d47229d3
--- /dev/null
+++ b/backend/api/src/models/github_pull_requests/commit.rs
@@ -0,0 +1,23 @@
+use diesel::Identifiable;
+use domain::{GithubPullRequestId, GithubUserId};
+use infrastructure::database::schema::github_pull_request_commits;
+use serde::{Deserialize, Serialize};
+
+#[derive(
+	Debug, Clone, Insertable, Identifiable, AsChangeset, Queryable, Serialize, Deserialize, Model,
+)]
+#[diesel(primary_key(pull_request_id, sha))]
+pub struct GithubPullRequestCommit {
+	pub sha: String,
+	pub pull_request_id: GithubPullRequestId,
+	pub html_url: String,
+	pub author_id: GithubUserId,
+}
+
+impl Identifiable for GithubPullRequestCommit {
+	type Id = (GithubPullRequestId, String);
+
+	fn id(self) -> Self::Id {
+		(self.pull_request_id, self.sha)
+	}
+}
diff --git a/backend/api/src/models/github_pull_requests/mod.rs b/backend/api/src/models/github_pull_requests/mod.rs
new file mode 100644
index 0000000000..17be22e742
--- /dev/null
+++ b/backend/api/src/models/github_pull_requests/mod.rs
@@ -0,0 +1,87 @@
+mod commit;
+pub use commit::GithubPullRequestCommit as Commit;
+
+mod review;
+pub use review::GithubPullRequestReview as Review;
+
+mod closing_issues;
+pub use closing_issues::ClosingIssue;
+
+mod pull_request;
+pub use pull_request::GithubPullRequest as Inner;
+
+#[derive(Debug, Clone)]
+pub struct PullRequest {
+	pub inner: Inner,
+	pub commits: Option<Vec<Commit>>,
+	pub reviews: Option<Vec<Review>>,
+	pub closing_issues: Option<Vec<ClosingIssue>>,
+}
+
+impl From<domain::GithubPullRequest> for PullRequest {
+	fn from(pull_request: domain::GithubPullRequest) -> Self {
+		Self {
+			inner: Inner {
+				id: pull_request.id,
+				repo_id: pull_request.repo_id,
+				number: pull_request.number,
+				created_at: pull_request.created_at.naive_utc(),
+				author_id: pull_request.author.id,
+				merged_at: pull_request.merged_at.map(|date| date.naive_utc()),
+				status: pull_request.status.into(),
+				title: pull_request.title,
+				html_url: pull_request.html_url.to_string(),
+				closed_at: pull_request.closed_at.map(|date| date.naive_utc()),
+				draft: pull_request.draft,
+				ci_checks: None,
+			},
+			commits: None,
+			reviews: None,
+			closing_issues: None,
+		}
+	}
+}
+
+impl From<domain::GithubFullPullRequest> for PullRequest {
+	fn from(from: domain::GithubFullPullRequest) -> Self {
+		let mut pull_request = Self::from(from.inner);
+		pull_request.inner.ci_checks = from.ci_checks.map(Into::into);
+		pull_request.commits = from.commits.map(|commits| {
+			commits
+				.into_iter()
+				.map(|c| Commit {
+					sha: c.sha,
+					pull_request_id: pull_request.inner.id,
+					html_url: c.html_url.to_string(),
+					author_id: c.author.id,
+				})
+				.collect()
+		});
+
+		pull_request.reviews = from.reviews.map(|reviews| {
+			reviews
+				.into_iter()
+				.map(|review| Review {
+					id: review.id().to_string(),
+					pull_request_id: review.pull_request_id,
+					reviewer_id: review.reviewer.id,
+					outcome: review.outcome.map(Into::into),
+					status: review.status.into(),
+					submitted_at: review.submitted_at.map(|date| date.naive_utc()),
+				})
+				.collect()
+		});
+
+		pull_request.closing_issues = from.closing_issue_ids.map(|closing_issue_ids| {
+			closing_issue_ids
+				.into_iter()
+				.map(|github_issue_id| ClosingIssue {
+					github_issue_id,
+					github_pull_request_id: pull_request.inner.id,
+				})
+				.collect()
+		});
+
+		pull_request
+	}
+}
diff --git a/backend/api/src/models/github_pull_requests/pull_request.rs b/backend/api/src/models/github_pull_requests/pull_request.rs
new file mode 100644
index 0000000000..9e75081b6d
--- /dev/null
+++ b/backend/api/src/models/github_pull_requests/pull_request.rs
@@ -0,0 +1,34 @@
+use chrono::NaiveDateTime;
+use diesel::Identifiable;
+use domain::{GithubPullRequestId, GithubPullRequestNumber, GithubRepoId, GithubUserId};
+use infrastructure::database::{
+	enums::{GithubCiChecks, GithubPullRequestStatus},
+	schema::github_pull_requests,
+};
+use serde::{Deserialize, Serialize};
+
+#[derive(
+	Debug, Clone, Insertable, AsChangeset, Identifiable, Queryable, Serialize, Deserialize, Model,
+)]
+pub struct GithubPullRequest {
+	pub id: GithubPullRequestId,
+	pub repo_id: GithubRepoId,
+	pub number: GithubPullRequestNumber,
+	pub created_at: NaiveDateTime,
+	pub author_id: GithubUserId,
+	pub merged_at: Option<NaiveDateTime>,
+	pub status: GithubPullRequestStatus,
+	pub title: String,
+	pub html_url: String,
+	pub closed_at: Option<NaiveDateTime>,
+	pub draft: bool,
+	pub ci_checks: Option<GithubCiChecks>,
+}
+
+impl Identifiable for GithubPullRequest {
+	type Id = GithubPullRequestId;
+
+	fn id(self) -> Self::Id {
+		self.id
+	}
+}
diff --git a/backend/api/src/models/github_pull_requests/review.rs b/backend/api/src/models/github_pull_requests/review.rs
new file mode 100644
index 0000000000..c5d8ca2aa9
--- /dev/null
+++ b/backend/api/src/models/github_pull_requests/review.rs
@@ -0,0 +1,28 @@
+use chrono::NaiveDateTime;
+use diesel::Identifiable;
+use domain::{GithubPullRequestId, GithubUserId};
+use infrastructure::database::{
+	enums::{GithubCodeReviewOutcome, GithubCodeReviewStatus},
+	schema::github_pull_request_reviews,
+};
+use serde::{Deserialize, Serialize};
+
+#[derive(
+	Debug, Clone, Insertable, Identifiable, AsChangeset, Queryable, Serialize, Deserialize, Model,
+)]
+pub struct GithubPullRequestReview {
+	pub pull_request_id: GithubPullRequestId,
+	pub reviewer_id: GithubUserId,
+	pub status: GithubCodeReviewStatus,
+	pub outcome: Option<GithubCodeReviewOutcome>,
+	pub submitted_at: Option<NaiveDateTime>,
+	pub id: String,
+}
+
+impl Identifiable for GithubPullRequestReview {
+	type Id = String;
+
+	fn id(self) -> Self::Id {
+		self.id
+	}
+}
diff --git a/backend/api/src/models/github_repo_indexes/mod.rs b/backend/api/src/models/github_repo_indexes/mod.rs
new file mode 100644
index 0000000000..0e79487e5e
--- /dev/null
+++ b/backend/api/src/models/github_repo_indexes/mod.rs
@@ -0,0 +1,46 @@
+mod repository;
+use chrono::NaiveDateTime;
+use diesel::Identifiable;
+use domain::GithubRepoId;
+use infrastructure::database::schema::github_repo_indexes;
+pub use repository::Repository;
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+
+#[derive(
+	Debug,
+	Default,
+	Clone,
+	Insertable,
+	AsChangeset,
+	Identifiable,
+	Queryable,
+	Serialize,
+	Deserialize,
+	Model,
+)]
+#[diesel(table_name = github_repo_indexes, primary_key(repo_id))]
+pub struct GithubRepoIndex {
+	pub repo_id: GithubRepoId,
+	pub repo_indexer_state: Option<Value>,
+	pub issues_indexer_state: Option<Value>,
+	pub pull_requests_indexer_state: Option<Value>,
+	pub indexed_at: Option<NaiveDateTime>,
+}
+
+impl GithubRepoIndex {
+	pub fn new(repo_id: GithubRepoId) -> Self {
+		Self {
+			repo_id,
+			..Default::default()
+		}
+	}
+}
+
+impl Identifiable for GithubRepoIndex {
+	type Id = GithubRepoId;
+
+	fn id(self) -> Self::Id {
+		self.repo_id
+	}
+}
diff --git a/backend/api/src/models/github_repo_indexes/repository.rs b/backend/api/src/models/github_repo_indexes/repository.rs
new file mode 100644
index 0000000000..e1676845bf
--- /dev/null
+++ b/backend/api/src/models/github_repo_indexes/repository.rs
@@ -0,0 +1,151 @@
+use diesel::{ExpressionMethods, QueryDsl, RunQueryDsl};
+use domain::GithubRepoId;
+use infrastructure::{
+	contextualized_error::IntoContextualizedError,
+	database,
+	database::{schema::github_repo_indexes::dsl, Result},
+};
+
+use super::GithubRepoIndex;
+use crate::diesel::OptionalExtension;
+
+pub trait Repository: database::Repository<GithubRepoIndex> {
+	fn select_repo_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+	) -> Result<Option<serde_json::Value>>;
+	fn update_repo_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+		state: serde_json::Value,
+	) -> Result<()>;
+
+	fn select_issues_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+	) -> Result<Option<serde_json::Value>>;
+	fn update_issues_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+		state: serde_json::Value,
+	) -> Result<()>;
+
+	fn select_pull_requests_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+	) -> Result<Option<serde_json::Value>>;
+	fn update_pull_requests_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+		state: serde_json::Value,
+	) -> Result<()>;
+
+	fn start_indexing(&self, repo_id: GithubRepoId) -> Result<()>;
+}
+
+impl Repository for database::Client {
+	fn select_repo_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+	) -> Result<Option<serde_json::Value>> {
+		let mut connection = self.connection()?;
+		let state = dsl::github_repo_indexes
+			.select(dsl::repo_indexer_state)
+			.filter(dsl::repo_id.eq(repo_id))
+			.first(&mut *connection)
+			.optional()
+			.err_with_context(format!(
+				"select repo_indexer_state from github_repo_indexes where id={repo_id}"
+			))?
+			.flatten();
+		Ok(state)
+	}
+
+	fn update_repo_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+		state: serde_json::Value,
+	) -> Result<()> {
+		let mut connection = self.connection()?;
+		diesel::update(dsl::github_repo_indexes)
+			.set(dsl::repo_indexer_state.eq(state))
+			.filter(dsl::repo_id.eq(repo_id))
+			.execute(&mut *connection)
+			.err_with_context(format!(
+				"update github_repo_indexes set github_repo_indexes where id={repo_id}"
+			))?;
+		Ok(())
+	}
+
+	fn select_issues_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+	) -> Result<Option<serde_json::Value>> {
+		let mut connection = self.connection()?;
+		let state = dsl::github_repo_indexes
+			.select(dsl::issues_indexer_state)
+			.filter(dsl::repo_id.eq(repo_id))
+			.first(&mut *connection)
+			.err_with_context(format!(
+				"select issues_indexer_state from github_repo_indexes where id={repo_id}"
+			))?;
+		Ok(state)
+	}
+
+	fn update_issues_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+		state: serde_json::Value,
+	) -> Result<()> {
+		let mut connection = self.connection()?;
+		diesel::update(dsl::github_repo_indexes)
+			.set(dsl::issues_indexer_state.eq(state))
+			.filter(dsl::repo_id.eq(repo_id))
+			.execute(&mut *connection)
+			.err_with_context(format!(
+				"update github_repo_indexes set issues_indexer_state where id={repo_id}"
+			))?;
+		Ok(())
+	}
+
+	fn select_pull_requests_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+	) -> Result<Option<serde_json::Value>> {
+		let mut connection = self.connection()?;
+		let state = dsl::github_repo_indexes
+			.select(dsl::pull_requests_indexer_state)
+			.filter(dsl::repo_id.eq(repo_id))
+			.first(&mut *connection)
+			.err_with_context(format!(
+				"select pull_requests_indexer_state from github_repo_indexes where id={repo_id}"
+			))?;
+		Ok(state)
+	}
+
+	fn update_pull_requests_indexer_state(
+		&self,
+		repo_id: &GithubRepoId,
+		state: serde_json::Value,
+	) -> Result<()> {
+		let mut connection = self.connection()?;
+		diesel::update(dsl::github_repo_indexes)
+			.set(dsl::pull_requests_indexer_state.eq(state))
+			.filter(dsl::repo_id.eq(repo_id))
+			.execute(&mut *connection)
+			.err_with_context(format!(
+				"update github_repo_indexes set pull_requests_indexer_state where id={repo_id}"
+			))?;
+		Ok(())
+	}
+
+	fn start_indexing(&self, repo_id: GithubRepoId) -> Result<()> {
+		let mut connection = self.connection()?;
+		diesel::insert_into(dsl::github_repo_indexes)
+			.values(GithubRepoIndex::new(repo_id))
+			.on_conflict_do_nothing()
+			.execute(&mut *connection)
+			.err_with_context(format!("insert github_repo_indexes with id={repo_id}"))?;
+		Ok(())
+	}
+}
diff --git a/backend/api/src/models/github_user_indexes/mod.rs b/backend/api/src/models/github_user_indexes/mod.rs
new file mode 100644
index 0000000000..38d10c7131
--- /dev/null
+++ b/backend/api/src/models/github_user_indexes/mod.rs
@@ -0,0 +1,58 @@
+mod repository;
+use chrono::NaiveDateTime;
+use diesel::{pg::Pg, Identifiable, Queryable};
+use domain::GithubUserId;
+use infrastructure::database::schema::github_user_indexes;
+pub use repository::Repository;
+use serde::{Deserialize, Serialize};
+use serde_json::Value;
+
+#[derive(
+	Debug,
+	Default,
+	Clone,
+	Insertable,
+	Identifiable,
+	QueryableByName,
+	Serialize,
+	Deserialize,
+	ImmutableModel,
+)]
+#[diesel(table_name = github_user_indexes, primary_key(user_id))]
+pub struct GithubUserIndex {
+	pub user_id: GithubUserId,
+	pub indexed_at: Option<NaiveDateTime>,
+}
+
+impl<ST> Queryable<ST, Pg> for GithubUserIndex
+where
+	(
+		GithubUserId,
+		Option<Value>,
+		Option<Value>,
+		Option<NaiveDateTime>,
+	): Queryable<ST, Pg>,
+{
+	type Row = <(
+		GithubUserId,
+		Option<Value>,
+		Option<Value>,
+		Option<NaiveDateTime>,
+	) as Queryable<ST, Pg>>::Row;
+
+	fn build(row: Self::Row) -> diesel::deserialize::Result<Self> {
+		let (user_id, _, _, indexed_at) = Queryable::build(row)?;
+		Ok(Self {
+			user_id,
+			indexed_at,
+		})
+	}
+}
+
+impl Identifiable for GithubUserIndex {
+	type Id = GithubUserId;
+
+	fn id(self) -> Self::Id {
+		self.user_id
+	}
+}
diff --git a/backend/api/src/models/github_user_indexes/repository.rs b/backend/api/src/models/github_user_indexes/repository.rs
new file mode 100644
index 0000000000..bc9eed7e95
--- /dev/null
+++ b/backend/api/src/models/github_user_indexes/repository.rs
@@ -0,0 +1,56 @@
+use diesel::{ExpressionMethods, OptionalExtension, QueryDsl, RunQueryDsl};
+use domain::GithubUserId;
+use infrastructure::{
+	contextualized_error::IntoContextualizedError,
+	database,
+	database::{schema::github_user_indexes::dsl, Result},
+};
+
+use super::GithubUserIndex;
+
+pub trait Repository: database::ImmutableRepository<GithubUserIndex> {
+	fn select_user_indexer_state(
+		&self,
+		user_id: &GithubUserId,
+	) -> Result<Option<serde_json::Value>>;
+	fn update_user_indexer_state(
+		&self,
+		user_id: &GithubUserId,
+		state: serde_json::Value,
+	) -> Result<()>;
+}
+
+impl Repository for database::Client {
+	fn select_user_indexer_state(
+		&self,
+		user_id: &GithubUserId,
+	) -> Result<Option<serde_json::Value>> {
+		let mut connection = self.connection()?;
+		let state = dsl::github_user_indexes
+			.select(dsl::user_indexer_state)
+			.filter(dsl::user_id.eq(user_id))
+			.first(&mut *connection)
+			.optional()
+			.err_with_context(format!(
+				"select user_indexer_state from github_user_indexes where user_id={user_id}"
+			))?
+			.flatten();
+		Ok(state)
+	}
+
+	fn update_user_indexer_state(
+		&self,
+		user_id: &GithubUserId,
+		state: serde_json::Value,
+	) -> Result<()> {
+		let mut connection = self.connection()?;
+		diesel::update(dsl::github_user_indexes)
+			.set(dsl::user_indexer_state.eq(state))
+			.filter(dsl::user_id.eq(user_id))
+			.execute(&mut *connection)
+			.err_with_context(format!(
+				"update github_user_indexes set user_indexer_state where user_id={user_id}"
+			))?;
+		Ok(())
+	}
+}
diff --git a/backend/api/src/models/mod.rs b/backend/api/src/models/mod.rs
index 063b315eee..3d56cc49e4 100644
--- a/backend/api/src/models/mod.rs
+++ b/backend/api/src/models/mod.rs
@@ -1,34 +1,68 @@
-mod crypto_usd_quotes;
-pub use crypto_usd_quotes::CryptoUsdQuote;
-
+mod applications;
+mod budgets;
 mod contact_informations;
-pub use contact_informations::{ContactInformation, Repository as ContactInformationsRepository};
-
+mod crypto_usd_quotes;
+mod events;
+mod github_issues;
+pub mod github_pull_request_indexes;
+pub mod github_pull_requests;
+mod github_repo_indexes;
+mod github_user_indexes;
 mod ignored_contributions;
-pub use ignored_contributions::IgnoredContribution;
-
+mod onboarding;
+mod payment_requests;
+mod payments;
+mod payout_info;
 mod pending_project_leader_invitations;
-pub use pending_project_leader_invitations::{
-	Id as PendingProjectLeaderInvitationId, PendingProjectLeaderInvitation,
-};
-
 mod project_details;
-pub use project_details::ProjectDetails;
-
+mod project_github_repos;
+mod project_leads;
+mod projects;
+mod projects_budgets;
+mod projects_contributors;
+mod projects_pending_contributors;
+mod projects_rewarded_users;
 mod projects_sponsors;
-pub use projects_sponsors::ProjectsSponsor;
-
 mod sponsors;
-pub use sponsors::Sponsor;
+mod user_profile_info;
+mod work_items;

-mod onboarding;
+pub use applications::Application;
+pub use budgets::Budget;
+pub use contact_informations::{ContactInformation, Repository as ContactInformationsRepository};
+pub use crypto_usd_quotes::CryptoUsdQuote;
+pub use events::{Event, Repository as EventRepository};
+pub use github_issues::GithubIssue;
+pub use github_pull_request_indexes::{
+	GithubPullRequestIndex, Repository as GithubPullRequestIndexRepository,
+};
+pub use github_pull_requests::PullRequest as GithubPullRequest;
+pub use github_repo_indexes::{GithubRepoIndex, Repository as GithubRepoIndexRepository};
+pub use github_user_indexes::{GithubUserIndex, Repository as GithubUserIndexRepository};
+pub use ignored_contributions::IgnoredContribution;
 pub use onboarding::Onboarding;
-
-mod payout_info;
+pub use payment_requests::PaymentRequest;
+pub use payments::Payment;
 pub use payout_info::{
 	BankAccount, CompanyIdentity, Identity, Location, PersonIdentity,
 	Repository as PayoutInfoRepository, UserPayoutInfo, Wallet,
 };
-
-mod user_profile_info;
+pub use pending_project_leader_invitations::{
+	Id as PendingProjectLeaderInvitationId, PendingProjectLeaderInvitation,
+};
+pub use project_details::ProjectDetails;
+pub use project_github_repos::{ProjectGithubRepo, Repository as ProjectGithubRepoRepository};
+pub use project_leads::ProjectLead;
+pub use projects::Project;
+pub use projects_budgets::ProjectsBudget;
+pub use projects_contributors::{ProjectsContributor, Repository as ProjectsContributorRepository};
+pub use projects_pending_contributors::{
+	ProjectsPendingContributor, Repository as ProjectsPendingContributorRepository,
+};
+pub use projects_rewarded_users::{
+	ProjectsRewardedUser, Repository as ProjectsRewardedUserRepository,
+};
+pub use projects_sponsors::ProjectsSponsor;
+pub use sponsors::Sponsor;
 pub use user_profile_info::{Repository as UserProfileInfoRepository, UserProfileInfo};
+pub use work_items::{Repository as WorkItemRepository, WorkItem};
diff --git a/backend/event-listeners/src/models/payment_requests.rs b/backend/api/src/models/payment_requests.rs
similarity index 100%
rename from backend/event-listeners/src/models/payment_requests.rs
rename to backend/api/src/models/payment_requests.rs
diff --git a/backend/event-listeners/src/models/payments.rs b/backend/api/src/models/payments.rs
similarity index 100%
rename from backend/event-listeners/src/models/payments.rs
rename to backend/api/src/models/payments.rs
diff --git a/backend/api/src/models/project_github_repos/mod.rs b/backend/api/src/models/project_github_repos/mod.rs
new file mode 100644
index 0000000000..f3562b56c5
--- /dev/null
+++ b/backend/api/src/models/project_github_repos/mod.rs
@@ -0,0 +1,20 @@
+mod repository;
+use diesel::Identifiable;
+use domain::{GithubRepoId, ProjectId};
+use infrastructure::database::schema::project_github_repos;
+pub use repository::Repository;
+
+#[derive(Debug, Insertable, Identifiable, Queryable, ImmutableModel)]
+#[diesel(primary_key(project_id, github_repo_id))]
+pub struct ProjectGithubRepo {
+	pub project_id: ProjectId,
+	pub github_repo_id: GithubRepoId,
+}
+
+impl Identifiable for ProjectGithubRepo {
+	type Id = (ProjectId, GithubRepoId);
+
+	fn id(self) -> Self::Id {
+		(self.project_id, self.github_repo_id)
+	}
+}
diff --git a/backend/api/src/models/project_github_repos/repository.rs b/backend/api/src/models/project_github_repos/repository.rs
new file mode 100644
index 0000000000..201b443f12
--- /dev/null
+++ b/backend/api/src/models/project_github_repos/repository.rs
@@ -0,0 +1,27 @@
+use diesel::{ExpressionMethods, QueryDsl, RunQueryDsl};
+use domain::{GithubRepoId, ProjectId};
+use infrastructure::{
+	contextualized_error::IntoContextualizedError,
+	database,
+	database::{schema::project_github_repos::dsl, Result},
+};
+
+use super::ProjectGithubRepo;
+
+pub trait Repository: database::ImmutableRepository<ProjectGithubRepo> {
+	fn find_projects_of_repo(&self, github_repo_id: &GithubRepoId) -> Result<Vec<ProjectId>>;
+}
+
+impl Repository for database::Client {
+	fn find_projects_of_repo(&self, github_repo_id: &GithubRepoId) -> Result<Vec<ProjectId>> {
+		let mut connection = self.connection()?;
+		let projects = dsl::project_github_repos
+			.select(dsl::project_id)
+			.filter(dsl::github_repo_id.eq(github_repo_id))
+			.load(&mut *connection)
+			.err_with_context(format!(
+				"select project_id from project_github_repos where github_repo_id={github_repo_id}"
+			))?;
+		Ok(projects)
+	}
+}
diff --git a/backend/event-listeners/src/models/project_leads.rs b/backend/api/src/models/project_leads.rs
similarity index 100%
rename from backend/event-listeners/src/models/project_leads.rs
rename to backend/api/src/models/project_leads.rs
diff --git a/backend/event-listeners/src/models/projects.rs b/backend/api/src/models/projects.rs
similarity index 100%
rename from backend/event-listeners/src/models/projects.rs
rename to backend/api/src/models/projects.rs
diff --git a/backend/event-listeners/src/models/projects_budgets.rs b/backend/api/src/models/projects_budgets.rs
similarity index 100%
rename from backend/event-listeners/src/models/projects_budgets.rs
rename to backend/api/src/models/projects_budgets.rs
diff --git a/backend/api/src/models/projects_contributors/mod.rs b/backend/api/src/models/projects_contributors/mod.rs
new file mode 100644
index 0000000000..ef0b7398d7
--- /dev/null
+++ b/backend/api/src/models/projects_contributors/mod.rs
@@ -0,0 +1,20 @@
+mod repository;
+use diesel::Identifiable;
+use domain::{GithubUserId, ProjectId};
+use infrastructure::database::schema::projects_contributors;
+pub use repository::Repository;
+
+#[derive(Debug, Insertable, Identifiable, Queryable, ImmutableModel)]
+#[diesel(primary_key(project_id, github_user_id))]
+pub struct ProjectsContributor {
+	pub project_id: ProjectId,
+	pub github_user_id: GithubUserId,
+}
+
+impl Identifiable for ProjectsContributor {
+	type Id = (ProjectId, GithubUserId);
+
+	fn id(self) -> Self::Id {
+		(self.project_id, self.github_user_id)
+	}
+}
diff --git a/backend/api/src/models/projects_contributors/repository.rs b/backend/api/src/models/projects_contributors/repository.rs
new file mode 100644
index 0000000000..c8df31b01d
--- /dev/null
+++ b/backend/api/src/models/projects_contributors/repository.rs
@@ -0,0 +1,64 @@
+use diesel::{Connection, ExpressionMethods, QueryDsl, RunQueryDsl};
+use domain::{GithubRepoId, GithubUserId, ProjectId};
+use infrastructure::{
+	contextualized_error::IntoContextualizedError,
+	database::{
+		self,
+		enums::ContributionStatus,
+		schema::{contributions, project_github_repos, projects_contributors::dsl},
+		Result,
+	},
+};
+
+use super::ProjectsContributor;
+
+pub trait Repository: database::ImmutableRepository<ProjectsContributor> {
+	fn refresh_project_contributor_list(&self, project_id: &ProjectId)
+	-> Result<Vec<GithubUserId>>;
+}
+
+impl Repository for database::Client {
+	fn refresh_project_contributor_list(
+		&self,
+		project_id: &ProjectId,
+	) -> Result<Vec<GithubUserId>> {
+		let mut connection = self.connection()?;
+
+		let mut contributors: Vec<GithubUserId> = vec![];
+		connection
+			.transaction::<_, diesel::result::Error, _>(|tx| {
+				diesel::delete(dsl::projects_contributors)
+					.filter(dsl::project_id.eq(project_id))
+					.execute(&mut *tx)?;
+
+				let repos: Vec<GithubRepoId> = project_github_repos::dsl::project_github_repos
+					.select(project_github_repos::dsl::github_repo_id)
+					.filter(project_github_repos::dsl::project_id.eq(project_id))
+					.load(&mut *tx)?;
+
+				contributors = contributions::dsl::contributions
+					.select(contributions::dsl::user_id)
+					.distinct()
+					.filter(contributions::dsl::repo_id.eq_any(repos))
+					.filter(contributions::dsl::status.eq(ContributionStatus::Complete))
+					.load(&mut *tx)?;
+
+				contributors.iter().try_for_each(|user_id| {
+					diesel::insert_into(dsl::projects_contributors)
+						.values((
+							dsl::project_id.eq(project_id),
+							dsl::github_user_id.eq(user_id),
+						))
+						.on_conflict_do_nothing()
+						.execute(&mut *tx)?;
+					Ok::<(), diesel::result::Error>(())
+				})?;
+
+				Ok(())
+			})
+			.err_with_context(format!(
+				"refreshing contributors of project with id={project_id}"
+			))?;
+		Ok(contributors)
+	}
+}
diff --git a/backend/api/src/models/projects_pending_contributors/mod.rs b/backend/api/src/models/projects_pending_contributors/mod.rs
new file mode 100644
index 0000000000..38416f7a50
--- /dev/null
+++ b/backend/api/src/models/projects_pending_contributors/mod.rs
@@ -0,0 +1,20 @@
+mod repository;
+use diesel::Identifiable;
+use domain::{GithubUserId, ProjectId};
+use infrastructure::database::schema::projects_pending_contributors;
+pub use repository::Repository;
+
+#[derive(Debug, Insertable, Identifiable, Queryable, ImmutableModel)]
+#[diesel(primary_key(project_id, github_user_id))]
+pub struct ProjectsPendingContributor {
+	pub project_id: ProjectId,
+	pub github_user_id: GithubUserId,
+}
+
+impl Identifiable for ProjectsPendingContributor {
+	type Id = (ProjectId, GithubUserId);
+
+	fn id(self) -> Self::Id {
+		(self.project_id, self.github_user_id)
+	}
+}
diff --git a/backend/api/src/models/projects_pending_contributors/repository.rs b/backend/api/src/models/projects_pending_contributors/repository.rs
new file mode 100644
index 0000000000..d702c1afc6
--- /dev/null
+++ b/backend/api/src/models/projects_pending_contributors/repository.rs
@@ -0,0 +1,64 @@
+use diesel::{Connection, ExpressionMethods, QueryDsl, RunQueryDsl};
+use domain::{GithubRepoId, GithubUserId, ProjectId};
+use infrastructure::{
+	contextualized_error::IntoContextualizedError,
+	database,
+	database::{
+		schema::{contributions, project_github_repos, projects_pending_contributors::dsl},
+		Result,
+	},
+};
+
+use super::ProjectsPendingContributor;
+
+pub trait Repository: database::ImmutableRepository<ProjectsPendingContributor> {
+	fn refresh_project_pending_contributor_list(
+		&self,
+		project_id: &ProjectId,
+	) -> Result<Vec<GithubUserId>>;
+}
+
+impl Repository for database::Client {
+	fn refresh_project_pending_contributor_list(
+		&self,
+		project_id: &ProjectId,
+	) -> Result<Vec<GithubUserId>> {
+		let mut connection = self.connection()?;
+
+		let mut contributors: Vec<GithubUserId> = vec![];
+		connection
+			.transaction::<_, diesel::result::Error, _>(|tx| {
+				diesel::delete(dsl::projects_pending_contributors)
+					.filter(dsl::project_id.eq(project_id))
+					.execute(&mut *tx)?;
+
+				let repos: Vec<GithubRepoId> = project_github_repos::dsl::project_github_repos
+					.select(project_github_repos::dsl::github_repo_id)
+					.filter(project_github_repos::dsl::project_id.eq(project_id))
+					.load(&mut *tx)?;
+
+				contributors = contributions::dsl::contributions
+					.select(contributions::dsl::user_id)
+					.distinct()
+					.filter(contributions::dsl::repo_id.eq_any(repos))
+					.load(&mut *tx)?;
+
+				contributors.iter().try_for_each(|user_id| {
+					diesel::insert_into(dsl::projects_pending_contributors)
+						.values((
+							dsl::project_id.eq(project_id),
+							dsl::github_user_id.eq(user_id),
+						))
+						.on_conflict_do_nothing()
+						.execute(&mut *tx)?;
+					Ok::<(), diesel::result::Error>(())
+				})?;
+
+				Ok(())
+			})
+			.err_with_context(format!(
+				"refreshing pending contributors of project with id={project_id}"
+			))?;
+		Ok(contributors)
+	}
+}
diff --git a/backend/event-listeners/src/models/projects_rewarded_users/mod.rs b/backend/api/src/models/projects_rewarded_users/mod.rs
similarity index 100%
rename from backend/event-listeners/src/models/projects_rewarded_users/mod.rs
rename to backend/api/src/models/projects_rewarded_users/mod.rs
diff --git a/backend/event-listeners/src/models/projects_rewarded_users/repository.rs b/backend/api/src/models/projects_rewarded_users/repository.rs
similarity index 100%
rename from backend/event-listeners/src/models/projects_rewarded_users/repository.rs
rename to backend/api/src/models/projects_rewarded_users/repository.rs
diff --git a/backend/event-listeners/src/models/work_items/mod.rs b/backend/api/src/models/work_items/mod.rs
similarity index 100%
rename from backend/event-listeners/src/models/work_items/mod.rs
rename to backend/api/src/models/work_items/mod.rs
diff --git a/backend/event-listeners/src/models/work_items/repository.rs b/backend/api/src/models/work_items/repository.rs
similarity index 100%
rename from backend/event-listeners/src/models/work_items/repository.rs
rename to backend/api/src/models/work_items/repository.rs
diff --git a/backend/api/src/presentation/bootstrap.rs b/backend/api/src/presentation/bootstrap.rs
index 9fcfa0531e..db9e1e2429 100644
--- a/backend/api/src/presentation/bootstrap.rs
+++ b/backend/api/src/presentation/bootstrap.rs
@@ -1,11 +1,12 @@
 use std::sync::Arc;

 use anyhow::Result;
-use domain::AggregateRepository;
-use infrastructure::{amqp, amqp::CommandPublisherDecorator, database, github};
+use domain::{AggregateRepository, CompositePublisher, EventPublisher};
+use infrastructure::{amqp, database, event_bus::EXCHANGE_NAME, github};
 use rocket::{Build, Rocket};

 use crate::{
+	domain::projectors::{self, projections},
 	infrastructure::{simple_storage, web3::ens},
 	presentation::{graphql, http, http::github_client_pat_factory::GithubClientPatFactory},
 	Config,
@@ -25,15 +26,37 @@ pub async fn bootstrap(config: Config) -> Result<Rocket<Build>> {
 	let simple_storage = Arc::new(simple_storage::Client::new(config.s3.clone()).await?);
 	let github_client_pat_factory = GithubClientPatFactory::new(config.github_api_client.clone());

-	let rocket_build = http::serve(
-		config.clone(),
-		graphql::create_schema(),
+	let event_publisher = CompositePublisher::new(vec![
+		Arc::new(EventPublisher::new(
+			projectors::event_store::Projector::new(database.clone()),
+		)),
+		Arc::new(EventPublisher::new(projections::Projector::new(
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+			database.clone(),
+		))),
 		Arc::new(
 			amqp::Bus::new(config.amqp.clone())
 				.await?
-				.into_command_publisher(database.clone(), expected_processing_count_per_event()),
+				.as_publisher(amqp::Destination::exchange(EXCHANGE_NAME)),
 		),
-		Arc::new(amqp::Bus::new(config.amqp.clone()).await?),
+	]);
+
+	let rocket_build = http::serve(
+		config.clone(),
+		graphql::create_schema(),
+		Arc::new(event_publisher),
 		AggregateRepository::new(database.clone()),
 		AggregateRepository::new(database.clone()),
 		AggregateRepository::new(database.clone()),
@@ -53,15 +76,7 @@ pub async fn bootstrap(config: Config) -> Result<Rocket<Build>> {
 		dusty_bot_api_client,
 		Arc::new(ens::Client::new(config.web3)?),
 		simple_storage,
-		Arc::new(amqp::Bus::new(config.amqp).await?),
 		Arc::new(github_client_pat_factory),
 	);
 	Ok(rocket_build)
 }
-
-fn expected_processing_count_per_event() -> i32 {
-	std::env::var("DOMAIN_EVENT_PROJECTORS_COUNT")
-		.unwrap_or_default()
-		.parse()
-		.unwrap_or(2)
-}
diff --git a/backend/api/src/presentation/graphql/context.rs b/backend/api/src/presentation/graphql/context.rs
index 5a4a154d2e..18d5069199 100644
--- a/backend/api/src/presentation/graphql/context.rs
+++ b/backend/api/src/presentation/graphql/context.rs
@@ -1,8 +1,7 @@
 use std::sync::Arc;

-use domain::{AggregateRepository, GithubUserId, Payment, Project, UserId};
+use domain::{AggregateRepository, Event, GithubUserId, Payment, Project, Publisher, UserId};
 use infrastructure::{
-	amqp,
 	database::{ImmutableRepository, Repository},
 	github,
 };
@@ -54,7 +53,7 @@ impl Context {
 		github_api_client: Arc<github::Client>,
 		ens: Arc<ens::Client>,
 		simple_storage: Arc<dyn ImageStoreService>,
-		bus: Arc<amqp::Bus>,
+		bus: Arc<dyn Publisher<Event>>,
 	) -> Self {
 		Self {
 			caller_permissions,
diff --git a/backend/api/src/presentation/http/mod.rs b/backend/api/src/presentation/http/mod.rs
index 9d4c32b5a6..ba5b424e70 100644
--- a/backend/api/src/presentation/http/mod.rs
+++ b/backend/api/src/presentation/http/mod.rs
@@ -4,7 +4,6 @@ use ::domain::{AggregateRepository, Project};
 use domain::{Budget, Event, GithubFetchService, Payment, Publisher};
 pub use http::Config;
 use infrastructure::{
-	amqp::{self, CommandMessage, UniqueMessage},
 	database::{ImmutableRepository, Repository},
 	github,
 };
@@ -30,8 +29,7 @@ mod usecases;
 pub fn serve(
 	config: crate::Config,
 	schema: graphql::Schema,
-	command_bus: Arc<dyn Publisher<CommandMessage<Event>>>,
-	event_bus: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	event_bus: Arc<dyn Publisher<Event>>,
 	project_repository: AggregateRepository<Project>,
 	budget_repository: AggregateRepository<Budget>,
 	payment_repository: AggregateRepository<Payment>,
@@ -53,7 +51,6 @@ pub fn serve(
 	dusty_bot_service: Arc<dyn DustyBotService>,
 	ens: Arc<ens::Client>,
 	simple_storage: Arc<dyn ImageStoreService>,
-	bus: Arc<amqp::Bus>,
 	github_client_pat_factory: Arc<GithubClientPatFactory>,
 ) -> Rocket<Build> {
 	let update_user_profile_info_usecase = application::user::update_profile_info::Usecase::new(
@@ -69,13 +66,12 @@ pub fn serve(
 	);

 	let cancel_payment_usecase =
-		application::payment::cancel::Usecase::new(bus.clone(), payment_repository.clone());
+		application::payment::cancel::Usecase::new(event_bus.clone(), payment_repository.clone());

 	rocket::custom(http::config::rocket("backend/api/Rocket.toml"))
 		.manage(config.http.clone())
 		.manage(config)
 		.manage(schema)
-		.manage(command_bus)
 		.manage(event_bus)
 		.manage(project_repository)
 		.manage(budget_repository)
@@ -92,7 +88,6 @@ pub fn serve(
 		.manage(github_api_client)
 		.manage(ens)
 		.manage(simple_storage)
-		.manage(bus)
 		.manage(update_user_profile_info_usecase)
 		.manage(create_github_issue_usecase)
 		.manage(github_client_pat_factory)
diff --git a/backend/api/src/presentation/http/routes/graphql.rs b/backend/api/src/presentation/http/routes/graphql.rs
index 2b555f0c92..c72c1bd3ae 100644
--- a/backend/api/src/presentation/http/routes/graphql.rs
+++ b/backend/api/src/presentation/http/routes/graphql.rs
@@ -1,8 +1,7 @@
 use std::sync::Arc;

-use domain::{AggregateRepository, Payment, Project};
+use domain::{AggregateRepository, Event, Payment, Project, Publisher};
 use infrastructure::{
-	amqp::{self},
 	database::{ImmutableRepository, Repository},
 	github,
 };
@@ -43,7 +42,7 @@ pub async fn get_graphql_handler(
 	onboarding_repository: &State<Arc<dyn Repository<Onboarding>>>,
 	contact_informations_repository: &State<Arc<dyn ContactInformationsRepository>>,
 	github_api_client: &State<Arc<github::Client>>,
-	bus: &State<Arc<amqp::Bus>>,
+	bus: &State<Arc<dyn Publisher<Event>>>,
 	ens: &State<Arc<ens::Client>>,
 	simple_storage: &State<Arc<dyn ImageStoreService>>,
 ) -> GraphQLResponse {
@@ -86,7 +85,7 @@ pub async fn post_graphql_handler(
 	onboarding_repository: &State<Arc<dyn Repository<Onboarding>>>,
 	contact_informations_repository: &State<Arc<dyn ContactInformationsRepository>>,
 	github_api_client: &State<Arc<github::Client>>,
-	bus: &State<Arc<amqp::Bus>>,
+	bus: &State<Arc<dyn Publisher<Event>>>,
 	ens: &State<Arc<ens::Client>>,
 	simple_storage: &State<Arc<dyn ImageStoreService>>,
 ) -> GraphQLResponse {
diff --git a/backend/api/tests/budget_allocation_it.rs b/backend/api/tests/budget_allocation_it.rs
index 10fe191ffc..555805ce52 100644
--- a/backend/api/tests/budget_allocation_it.rs
+++ b/backend/api/tests/budget_allocation_it.rs
@@ -2,11 +2,12 @@ mod context;
 mod models;

 use anyhow::Result;
-use api::{models::Sponsor, presentation::http::routes::projects::budgets::Response};
-use domain::{
-	currencies, sponsor, Budget, BudgetEvent, BudgetId, Event, Project, ProjectEvent, ProjectId,
+use api::{models as api_models, presentation::http::routes::projects::budgets::Response};
+use domain::{currencies, sponsor, BudgetEvent, BudgetId, Event, ProjectEvent, ProjectId};
+use infrastructure::{
+	database::{enums::Currency, ImmutableRepository},
+	event_bus::EXCHANGE_NAME,
 };
-use infrastructure::database::ImmutableRepository;
 use olog::info;
 use rocket::{
 	http::{ContentType, Status},
@@ -57,12 +58,12 @@ impl<'a> Test<'a> {
 		let project_id = ProjectId::new();
 		let sponsor_id = sponsor::Id::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![ProjectEvent::Created { id: project_id }],
-		)?;
+		self.context
+			.event_publisher
+			.publish_many(&[ProjectEvent::Created { id: project_id }.into()])
+			.await?;

-		self.context.database.client.insert(Sponsor {
+		self.context.database.client.insert(api_models::Sponsor {
 			id: sponsor_id,
 			..Default::default()
 		})?;
@@ -102,7 +103,7 @@ impl<'a> Test<'a> {
 				budget_id,
 				currency: currencies::USD
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		assert_eq!(
@@ -110,7 +111,7 @@ impl<'a> Test<'a> {
 				id: budget_id,
 				currency: currencies::USD
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		assert_eq!(
@@ -119,7 +120,17 @@ impl<'a> Test<'a> {
 				amount: dec!(1523),
 				sponsor_id: Some(sponsor_id)
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
+		);
+
+		assert_eq!(
+			vec![api_models::Budget {
+				id: budget_id,
+				currency: Currency::Usd,
+				initial_amount: dec!(1523),
+				remaining_amount: dec!(1523)
+			}],
+			self.context.database.client.list().unwrap()
 		);

 		Ok(())
@@ -132,32 +143,29 @@ impl<'a> Test<'a> {
 		let project_id = ProjectId::new();
 		let budget_id = BudgetId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: dec!(1_000),
 					sponsor_id: None,
-				},
-			],
-		)?;
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"amount":523,
@@ -189,7 +197,7 @@ impl<'a> Test<'a> {
 				amount: dec!(523),
 				sponsor_id: None
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		Ok(())
@@ -202,32 +210,29 @@ impl<'a> Test<'a> {
 		let project_id = ProjectId::new();
 		let usd_budget_id = BudgetId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id: usd_budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: usd_budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: usd_budget_id,
 					amount: dec!(1_000),
 					sponsor_id: None,
-				},
-			],
-		)?;
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"amount": 1,
@@ -262,7 +267,7 @@ impl<'a> Test<'a> {
 				budget_id: eth_budget_id,
 				currency: currencies::ETH
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		assert_eq!(
@@ -270,7 +275,7 @@ impl<'a> Test<'a> {
 				id: eth_budget_id,
 				currency: currencies::ETH
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		assert_eq!(
@@ -279,7 +284,7 @@ impl<'a> Test<'a> {
 				amount: dec!(1),
 				sponsor_id: None
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		Ok(())
@@ -292,10 +297,10 @@ impl<'a> Test<'a> {
 		let project_id = ProjectId::new();
 		let sponsor_id = sponsor::Id::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![ProjectEvent::Created { id: project_id }],
-		)?;
+		self.context
+			.event_publisher
+			.publish_many(&[ProjectEvent::Created { id: project_id }.into()])
+			.await?;

 		let request = json!({
 			"amount": 1523,
diff --git a/backend/api/tests/context/mod.rs b/backend/api/tests/context/mod.rs
index 24e9e2757d..012beef742 100644
--- a/backend/api/tests/context/mod.rs
+++ b/backend/api/tests/context/mod.rs
@@ -1,7 +1,14 @@
-use std::env;
+use std::{env, sync::Arc};

 use anyhow::Result;
-use api::{application::quotes, presentation::bootstrap::bootstrap, Config};
+use api::{
+	application::quotes,
+	domain::projectors::{self, projections},
+	presentation::bootstrap::bootstrap,
+	Config,
+};
+use domain::{CompositePublisher, Event, EventPublisher, Publisher};
+use infrastructure::event_bus::EXCHANGE_NAME;
 use presentation::http;
 use rocket::local::asynchronous::Client;
 use rstest::fixture;
@@ -33,6 +40,7 @@ pub struct Context<'a> {
 	pub web3: web3::Context<'a>,
 	pub coinmarketcap: coinmarketcap::Context<'a>,
 	pub quotes_syncer: quotes::sync::Usecase,
+	pub event_publisher: Arc<dyn Publisher<Event>>,
 	_environment: environment::Context,
 }

@@ -41,7 +49,7 @@ impl<'a> Context<'a> {
 		tracing_subscriber::fmt::init();

 		let database = database::Context::new(docker)?;
-		let amqp = amqp::Context::new(docker, vec![event_store::bus::QUEUE_NAME], vec![]).await?;
+		let amqp = amqp::Context::new(docker, vec![], vec![EXCHANGE_NAME]).await?;
 		let simple_storage = simple_storage::Context::new(docker)?;
 		let dusty_bot_github = github::Context::new(
 			docker,
@@ -102,6 +110,28 @@ impl<'a> Context<'a> {
 			coinmarketcap: coinmarketcap.config.clone(),
 		};

+		let event_publisher = CompositePublisher::new(vec![
+			Arc::new(EventPublisher::new(
+				projectors::event_store::Projector::new(database.client.clone()),
+			)),
+			Arc::new(EventPublisher::new(projections::Projector::new(
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+				database.client.clone(),
+			))),
+		]);
+
 		Ok(Self {
 			http_client: Client::tracked(bootstrap(config.clone()).await?).await?,
 			database,
@@ -113,6 +143,7 @@ impl<'a> Context<'a> {
 			web3,
 			coinmarketcap,
 			quotes_syncer: quotes::sync::Usecase::bootstrap(config.clone())?,
+			event_publisher: Arc::new(event_publisher),
 			_environment: environment::Context::new(),
 		})
 	}
diff --git a/backend/api/tests/create_and_close_issue_it.rs b/backend/api/tests/create_and_close_issue_it.rs
index e453bf7613..ac49559ecc 100644
--- a/backend/api/tests/create_and_close_issue_it.rs
+++ b/backend/api/tests/create_and_close_issue_it.rs
@@ -3,10 +3,7 @@ extern crate diesel;

 use anyhow::Result;
 use chrono::Utc;
-use domain::{
-	currencies, Budget, BudgetEvent, BudgetId, GithubRepoId, Project, ProjectEvent, ProjectId,
-	UserId,
-};
+use domain::{currencies, BudgetEvent, BudgetId, GithubRepoId, ProjectEvent, ProjectId, UserId};
 use olog::info;
 use rocket::http::{ContentType, Header, Status};
 use rstest::rstest;
@@ -48,38 +45,36 @@ impl<'a> Test<'a> {
 		let github_repo_id = GithubRepoId::from(1111u64);
 		let budget_id = BudgetId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id }.into(),
 				ProjectEvent::BudgetLinked {
 					id,
 					budget_id,
 					currency: currencies::USD,
-				},
-				ProjectEvent::GithubRepoLinked { id, github_repo_id },
+				}
+				.into(),
+				ProjectEvent::GithubRepoLinked { id, github_repo_id }.into(),
 				ProjectEvent::LeaderAssigned {
 					id,
 					leader_id: UserId::new(),
 					assigned_at: Utc::now().naive_utc(),
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(10),
 					sponsor_id: None,
-				},
-			],
-		)?;
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"projectId": id.to_string(),
diff --git a/backend/api/tests/create_project_it.rs b/backend/api/tests/create_project_it.rs
index a5f9e0a6df..75cac1191a 100644
--- a/backend/api/tests/create_project_it.rs
+++ b/backend/api/tests/create_project_it.rs
@@ -5,7 +5,10 @@ use anyhow::Result;
 use api::{models::Sponsor, presentation::http::routes::projects};
 use diesel::RunQueryDsl;
 use domain::{currencies, sponsor, BudgetEvent, Event, ProjectEvent};
-use infrastructure::database::{schema::project_details, ImmutableRepository};
+use infrastructure::{
+	database::{schema::project_details, ImmutableRepository},
+	event_bus::EXCHANGE_NAME,
+};
 use olog::info;
 use rocket::{
 	http::{ContentType, Status},
@@ -70,7 +73,7 @@ impl<'a> Test<'a> {
 		let project_id = project.project_id;

 		assert_eq!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await,
+			self.context.amqp.listen(EXCHANGE_NAME).await,
 			Some(Event::Project(domain::ProjectEvent::Created {
 				id: project_id
 			}))
@@ -142,7 +145,7 @@ impl<'a> Test<'a> {
 		let budget_id = project.budget_id.unwrap();

 		assert_eq!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await,
+			self.context.amqp.listen(EXCHANGE_NAME).await,
 			Some(Event::Project(ProjectEvent::Created { id: project_id }))
 		);

@@ -152,7 +155,7 @@ impl<'a> Test<'a> {
 				id: project_id,
 				currency: currencies::USD
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		assert_eq!(
@@ -160,7 +163,7 @@ impl<'a> Test<'a> {
 				id: budget_id,
 				currency: currencies::USD
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		assert_eq!(
@@ -169,7 +172,7 @@ impl<'a> Test<'a> {
 				amount: dec!(1000),
 				sponsor_id: Some(sponsor_id)
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		Ok(())
diff --git a/backend/api/tests/models/events.rs b/backend/api/tests/models/events.rs
deleted file mode 100644
index 74ccc16706..0000000000
--- a/backend/api/tests/models/events.rs
+++ /dev/null
@@ -1,43 +0,0 @@
-use chrono::NaiveDateTime;
-use diesel::RunQueryDsl;
-use domain::{CommandId, EventSourcable, Identified};
-use infrastructure::{amqp::UniqueMessage, database::schema::events, event_store::Named};
-use serde::{Deserialize, Serialize};
-use serde_json::Value;
-
-use crate::context::Context;
-
-#[derive(Debug, Serialize, Deserialize, Insertable)]
-pub struct Event {
-	pub timestamp: NaiveDateTime,
-	pub aggregate_name: String,
-	pub aggregate_id: String,
-	pub payload: Value,
-	pub metadata: Value,
-	pub command_id: Option<CommandId>,
-}
-
-#[allow(unused)]
-pub fn store<A: Named + EventSourcable>(
-	context: &Context,
-	events: Vec<A::Event>,
-) -> anyhow::Result<()> {
-	let events: Vec<_> = events
-		.into_iter()
-		.map(UniqueMessage::new)
-		.map(|m| Event {
-			timestamp: *m.timestamp(),
-			aggregate_name: A::name(),
-			aggregate_id: m.payload().id().to_string(),
-			payload: serde_json::to_value(m.payload()).expect("Invalid payload"),
-			metadata: m.metadata().clone(),
-			command_id: m.command_id().map(Into::into),
-		})
-		.collect();
-
-	diesel::insert_into(events::table)
-		.values(events)
-		.execute(&mut *context.database.client.connection()?)?;
-
-	Ok(())
-}
diff --git a/backend/api/tests/models/mod.rs b/backend/api/tests/models/mod.rs
index 02ac1129e8..ff11436c0a 100644
--- a/backend/api/tests/models/mod.rs
+++ b/backend/api/tests/models/mod.rs
@@ -1,8 +1,5 @@
 mod project_details;
 pub use project_details::*;

-pub mod events;
-pub use events::Event;
-
 mod user_profile_info;
 pub use user_profile_info::*;
diff --git a/backend/api/tests/payment_it.rs b/backend/api/tests/payment_it.rs
index f2d4fe289f..94c092d531 100644
--- a/backend/api/tests/payment_it.rs
+++ b/backend/api/tests/payment_it.rs
@@ -8,10 +8,11 @@ use api::presentation::http::routes::payment;
 use assert_matches::assert_matches;
 use chrono::{Duration, Utc};
 use domain::{
-	blockchain::evm, currencies, Amount, Budget, BudgetEvent, BudgetId, Event, GithubPullRequestId,
-	GithubPullRequestNumber, GithubRepoId, GithubUserId, Payment, PaymentEvent, PaymentId,
-	PaymentReason, PaymentReceipt, PaymentWorkItem, Project, ProjectEvent, ProjectId, UserId,
+	blockchain::evm, currencies, Amount, BudgetEvent, BudgetId, Event, GithubPullRequestId,
+	GithubPullRequestNumber, GithubRepoId, GithubUserId, PaymentEvent, PaymentId, PaymentReason,
+	PaymentReceipt, PaymentWorkItem, ProjectEvent, ProjectId, UserId,
 };
+use infrastructure::event_bus::EXCHANGE_NAME;
 use olog::info;
 use rocket::{
 	http::{ContentType, Header, Status},
@@ -77,32 +78,29 @@ impl<'a> Test<'a> {
 		let budget_id = BudgetId::new();
 		let before = Utc::now().naive_utc();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
-			],
-		)?;
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"projectId": project_id,
@@ -154,11 +152,11 @@ impl<'a> Test<'a> {
 				id: budget_id,
 				amount: dec!(10)
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		assert_matches!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 			Event::Payment(event) => {
 				assert_matches!(event, PaymentEvent::Requested {
 					id,
@@ -204,32 +202,29 @@ impl<'a> Test<'a> {
 		let budget_id = BudgetId::new();
 		let before = Utc::now().naive_utc();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::ETH,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::ETH,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1),
 					sponsor_id: None,
-				},
-			],
-		)?;
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"projectId": project_id,
@@ -281,11 +276,11 @@ impl<'a> Test<'a> {
 				id: budget_id,
 				amount: dec!(0.00001)
 			}),
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 		);

 		assert_matches!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 			Event::Payment(event) => {
 				assert_matches!(event, PaymentEvent::Requested {
 					id,
@@ -330,32 +325,29 @@ impl<'a> Test<'a> {
 		let project_id = ProjectId::new();
 		let budget_id = BudgetId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
-			],
-		)?;
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"projectId": project_id,
@@ -369,7 +361,8 @@ impl<'a> Test<'a> {
 					"id": "123456",
 					"repoId": 498695724,
 					"number": 111
-				},{
+				},
+				{
 					"type": "PULL_REQUEST",
 					"id": "123456",
 					"repoId": 1181927,
@@ -412,32 +405,29 @@ impl<'a> Test<'a> {
 		let project_id = ProjectId::new();
 		let budget_id = BudgetId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
-			],
-		)?;
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"projectId": project_id,
@@ -490,46 +480,40 @@ impl<'a> Test<'a> {
 		let budget_id = BudgetId::new();
 		let payment_id = PaymentId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
-			],
-		)?;
-
-		models::events::store::<Payment>(
-			&self.context,
-			vec![PaymentEvent::Requested {
-				id: payment_id,
-				project_id,
-				requestor_id: UserId::new(),
-				recipient_id: GithubUserId::from(595505u64),
-				amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
-				duration_worked: Duration::hours(2),
-				reason: PaymentReason { work_items: vec![] },
-				requested_at: Utc::now().naive_utc(),
-			}],
-		)?;
+				}
+				.into(),
+				PaymentEvent::Requested {
+					id: payment_id,
+					project_id,
+					requestor_id: UserId::new(),
+					recipient_id: GithubUserId::from(595505u64),
+					amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
+					duration_worked: Duration::hours(2),
+					reason: PaymentReason { work_items: vec![] },
+					requested_at: Utc::now().naive_utc(),
+				}
+				.into(),
+			])
+			.await?;

 		// When
 		let response = self
@@ -555,7 +539,7 @@ impl<'a> Test<'a> {
 		);

 		assert_matches!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 			Event::Payment(_)
 		);

@@ -570,46 +554,40 @@ impl<'a> Test<'a> {
 		let budget_id = BudgetId::new();
 		let payment_id = PaymentId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
-			],
-		)?;
-
-		models::events::store::<Payment>(
-			&self.context,
-			vec![PaymentEvent::Requested {
-				id: payment_id,
-				project_id,
-				requestor_id: UserId::new(),
-				recipient_id: GithubUserId::from(595505u64),
-				amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
-				duration_worked: Duration::hours(2),
-				reason: PaymentReason { work_items: vec![] },
-				requested_at: Utc::now().naive_utc(),
-			}],
-		)?;
+				}
+				.into(),
+				PaymentEvent::Requested {
+					id: payment_id,
+					project_id,
+					requestor_id: UserId::new(),
+					recipient_id: GithubUserId::from(595505u64),
+					amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
+					duration_worked: Duration::hours(2),
+					reason: PaymentReason { work_items: vec![] },
+					requested_at: Utc::now().naive_utc(),
+				}
+				.into(),
+			])
+			.await?;

 		// When
 		let response = self
@@ -631,7 +609,7 @@ impl<'a> Test<'a> {
 		);

 		assert_matches!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 			Event::Payment(_)
 		);

@@ -646,46 +624,40 @@ impl<'a> Test<'a> {
 		let budget_id = BudgetId::new();
 		let payment_id = PaymentId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
-			],
-		)?;
-
-		models::events::store::<Payment>(
-			&self.context,
-			vec![PaymentEvent::Requested {
-				id: payment_id,
-				project_id,
-				requestor_id: UserId::new(),
-				recipient_id: GithubUserId::from(595505u64),
-				amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
-				duration_worked: Duration::hours(2),
-				reason: PaymentReason { work_items: vec![] },
-				requested_at: Utc::now().naive_utc(),
-			}],
-		)?;
+				}
+				.into(),
+				PaymentEvent::Requested {
+					id: payment_id,
+					project_id,
+					requestor_id: UserId::new(),
+					recipient_id: GithubUserId::from(595505u64),
+					amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
+					duration_worked: Duration::hours(2),
+					reason: PaymentReason { work_items: vec![] },
+					requested_at: Utc::now().naive_utc(),
+				}
+				.into(),
+			])
+			.await?;

 		// When
 		let response = self
@@ -721,50 +693,45 @@ impl<'a> Test<'a> {
 		let budget_id = BudgetId::new();
 		let payment_id = PaymentId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
+				}
+				.into(),
 				BudgetEvent::Spent {
 					id: budget_id,
 					amount: Decimal::from(100),
-				},
-			],
-		)?;
-
-		models::events::store::<Payment>(
-			&self.context,
-			vec![PaymentEvent::Requested {
-				id: payment_id,
-				project_id,
-				requestor_id: UserId::new(),
-				recipient_id: GithubUserId::from(595505u64),
-				amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
-				duration_worked: Duration::hours(2),
-				reason: PaymentReason { work_items: vec![] },
-				requested_at: Utc::now().naive_utc(),
-			}],
-		)?;
+				}
+				.into(),
+				PaymentEvent::Requested {
+					id: payment_id,
+					project_id,
+					requestor_id: UserId::new(),
+					recipient_id: GithubUserId::from(595505u64),
+					amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
+					duration_worked: Duration::hours(2),
+					reason: PaymentReason { work_items: vec![] },
+					requested_at: Utc::now().naive_utc(),
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"amount": 100,
@@ -800,7 +767,7 @@ impl<'a> Test<'a> {
 		let response: payment::receipts::Response = response.into_json().await.unwrap();

 		assert_matches!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 			Event::Payment(event) => {
 				assert_matches!(event, PaymentEvent::Processed {
 					id,
@@ -830,50 +797,45 @@ impl<'a> Test<'a> {
 		let budget_id = BudgetId::new();
 		let payment_id = PaymentId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::USD,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::USD,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
+				}
+				.into(),
 				BudgetEvent::Spent {
 					id: budget_id,
 					amount: Decimal::from(100),
-				},
-			],
-		)?;
-
-		models::events::store::<Payment>(
-			&self.context,
-			vec![PaymentEvent::Requested {
-				id: payment_id,
-				project_id,
-				requestor_id: UserId::new(),
-				recipient_id: GithubUserId::from(595505u64),
-				amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
-				duration_worked: Duration::hours(2),
-				reason: PaymentReason { work_items: vec![] },
-				requested_at: Utc::now().naive_utc(),
-			}],
-		)?;
+				}
+				.into(),
+				PaymentEvent::Requested {
+					id: payment_id,
+					project_id,
+					requestor_id: UserId::new(),
+					recipient_id: GithubUserId::from(595505u64),
+					amount: Amount::from_decimal(Decimal::from(100), currencies::USD),
+					duration_worked: Duration::hours(2),
+					reason: PaymentReason { work_items: vec![] },
+					requested_at: Utc::now().naive_utc(),
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"amount": 100,
@@ -909,7 +871,7 @@ impl<'a> Test<'a> {
 		let response: payment::receipts::Response = response.into_json().await.unwrap();

 		assert_matches!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 			Event::Payment(event) => {
 				assert_matches!(event, PaymentEvent::Processed {
 					id,
@@ -943,50 +905,45 @@ impl<'a> Test<'a> {
 		let budget_id = BudgetId::new();
 		let payment_id = PaymentId::new();

-		models::events::store::<Project>(
-			&self.context,
-			vec![
-				ProjectEvent::Created { id: project_id },
+		self.context
+			.event_publisher
+			.publish_many(&[
+				ProjectEvent::Created { id: project_id }.into(),
 				ProjectEvent::BudgetLinked {
 					id: project_id,
 					budget_id,
 					currency: currencies::STARK,
-				},
-			],
-		)?;
-
-		models::events::store::<Budget>(
-			&self.context,
-			vec![
+				}
+				.into(),
 				BudgetEvent::Created {
 					id: budget_id,
 					currency: currencies::STARK,
-				},
+				}
+				.into(),
 				BudgetEvent::Allocated {
 					id: budget_id,
 					amount: Decimal::from(1_000),
 					sponsor_id: None,
-				},
+				}
+				.into(),
 				BudgetEvent::Spent {
 					id: budget_id,
 					amount: Decimal::from(100),
-				},
-			],
-		)?;
-
-		models::events::store::<Payment>(
-			&self.context,
-			vec![PaymentEvent::Requested {
-				id: payment_id,
-				project_id,
-				requestor_id: UserId::new(),
-				recipient_id: GithubUserId::from(595505u64),
-				amount: Amount::from_decimal(Decimal::from(100), currencies::STARK),
-				duration_worked: Duration::hours(2),
-				reason: PaymentReason { work_items: vec![] },
-				requested_at: Utc::now().naive_utc(),
-			}],
-		)?;
+				}
+				.into(),
+				PaymentEvent::Requested {
+					id: payment_id,
+					project_id,
+					requestor_id: UserId::new(),
+					recipient_id: GithubUserId::from(595505u64),
+					amount: Amount::from_decimal(Decimal::from(100), currencies::STARK),
+					duration_worked: Duration::hours(2),
+					reason: PaymentReason { work_items: vec![] },
+					requested_at: Utc::now().naive_utc(),
+				}
+				.into(),
+			])
+			.await?;

 		let request = json!({
 			"amount": 100,
@@ -1022,7 +979,7 @@ impl<'a> Test<'a> {
 		let response: payment::receipts::Response = response.into_json().await.unwrap();

 		assert_matches!(
-			self.context.amqp.listen(event_store::bus::QUEUE_NAME).await.unwrap(),
+			self.context.amqp.listen(EXCHANGE_NAME).await.unwrap(),
 			Event::Payment(event) => {
 				assert_matches!(event, PaymentEvent::Processed {
 					id,
diff --git a/backend/common/domain/src/event/listener.rs b/backend/common/domain/src/event/listener.rs
new file mode 100644
index 0000000000..dc1d37a809
--- /dev/null
+++ b/backend/common/domain/src/event/listener.rs
@@ -0,0 +1,22 @@
+use async_trait::async_trait;
+use derive_new::new;
+
+use crate::{Message, PublisherError, SubscriberCallbackError};
+
+#[async_trait]
+pub trait Listener<E>: Send + Sync {
+	async fn on_event(&self, event: E) -> Result<(), SubscriberCallbackError>;
+}
+
+#[derive(Debug, new)]
+pub struct Publisher<L>(L);
+
+#[async_trait]
+impl<E: Message + Send + Sync, L: Listener<E>> crate::Publisher<E> for Publisher<L> {
+	async fn publish(&self, message: &E) -> Result<(), PublisherError> {
+		self.0
+			.on_event(message.clone())
+			.await
+			.map_err(|e| PublisherError::Send(e.into()))
+	}
+}
diff --git a/backend/common/domain/src/event.rs b/backend/common/domain/src/event/mod.rs
similarity index 87%
rename from backend/common/domain/src/event.rs
rename to backend/common/domain/src/event/mod.rs
index 495e14e8f2..a26e38ddae 100644
--- a/backend/common/domain/src/event.rs
+++ b/backend/common/domain/src/event/mod.rs
@@ -2,7 +2,10 @@ use std::fmt::Display;

 use serde::{Deserialize, Serialize};

-use crate::{ApplicationEvent, BudgetEvent, MessagePayload, PaymentEvent, ProjectEvent};
+use crate::{ApplicationEvent, BudgetEvent, PaymentEvent, ProjectEvent};
+
+mod listener;
+pub use listener::{Listener, Publisher};

 #[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]
 pub enum Event {
@@ -22,8 +25,6 @@ impl Display for Event {
 	}
 }

-impl MessagePayload for Event {}
-
 #[cfg(test)]
 mod test {
 	use assert_json_diff::assert_json_include;
diff --git a/backend/common/domain/src/lib.rs b/backend/common/domain/src/lib.rs
index d6cf7d154b..f0067d8b3b 100644
--- a/backend/common/domain/src/lib.rs
+++ b/backend/common/domain/src/lib.rs
@@ -4,7 +4,7 @@ mod value_objects;
 pub use value_objects::*;

 mod event;
-pub use event::Event;
+pub use event::{Event, Listener as EventListener, Publisher as EventPublisher};

 pub mod services;

@@ -21,8 +21,8 @@ pub use error::*;

 mod messaging;
 pub use messaging::{
-	Destination, Message, Payload as MessagePayload, Publisher, PublisherError, Subscriber,
-	SubscriberCallbackError, SubscriberError,
+	CompositePublisher, Message, Publisher, PublisherError, Subscriber, SubscriberCallbackError,
+	SubscriberError,
 };

 mod project;
diff --git a/backend/common/domain/src/messaging/message.rs b/backend/common/domain/src/messaging/message.rs
deleted file mode 100644
index e1b06e5611..0000000000
--- a/backend/common/domain/src/messaging/message.rs
+++ /dev/null
@@ -1,10 +0,0 @@
-use std::fmt::Debug;
-
-use olog::opentelemetry::propagation::Extractor;
-use serde::{de::DeserializeOwned, Serialize};
-use serde_json::Value;
-
-pub trait Message: Extractor + Serialize + DeserializeOwned + Debug + Clone {}
-pub trait Payload: Serialize + DeserializeOwned + Debug + Clone {}
-
-impl Payload for Value {}
diff --git a/backend/common/domain/src/messaging/mod.rs b/backend/common/domain/src/messaging/mod.rs
index 4c5d1454b0..0a8f09f8c5 100644
--- a/backend/common/domain/src/messaging/mod.rs
+++ b/backend/common/domain/src/messaging/mod.rs
@@ -1,13 +1,9 @@
-mod message;
-pub use message::{Message, Payload};
-
 mod publisher;
-pub use publisher::{Error as PublisherError, Publisher};
+pub use publisher::{
+	composite::Publisher as CompositePublisher, Error as PublisherError, Message, Publisher,
+};

 mod subscriber;
 pub use subscriber::{
 	CallbackError as SubscriberCallbackError, Error as SubscriberError, Subscriber,
 };
-
-mod destination;
-pub use destination::Destination;
diff --git a/backend/common/domain/src/messaging/publisher/composite.rs b/backend/common/domain/src/messaging/publisher/composite.rs
new file mode 100644
index 0000000000..6559aac082
--- /dev/null
+++ b/backend/common/domain/src/messaging/publisher/composite.rs
@@ -0,0 +1,29 @@
+use std::sync::Arc;
+
+use async_trait::async_trait;
+use derive_new::new;
+
+use super::Error;
+use crate::Message;
+
+#[derive(new)]
+pub struct Publisher<M: Message + Send + Sync> {
+	publishers: Vec<Arc<dyn super::Publisher<M>>>,
+}
+
+#[async_trait]
+impl<M: Message + Send + Sync> super::Publisher<M> for Publisher<M> {
+	async fn publish(&self, message: &M) -> Result<(), Error> {
+		for p in &self.publishers {
+			p.publish(message).await?;
+		}
+		Ok(())
+	}
+
+	async fn publish_many(&self, messages: &[M]) -> Result<(), Error> {
+		for p in &self.publishers {
+			p.publish_many(messages).await?;
+		}
+		Ok(())
+	}
+}
diff --git a/backend/common/domain/src/messaging/publisher/message.rs b/backend/common/domain/src/messaging/publisher/message.rs
new file mode 100644
index 0000000000..f9eb28aa54
--- /dev/null
+++ b/backend/common/domain/src/messaging/publisher/message.rs
@@ -0,0 +1,7 @@
+use std::fmt::Debug;
+
+use serde::{de::DeserializeOwned, Serialize};
+
+pub trait Message: Serialize + DeserializeOwned + Debug + Clone {}
+
+impl<T: Serialize + DeserializeOwned + Debug + Clone> Message for T {}
diff --git a/backend/common/domain/src/messaging/publisher.rs b/backend/common/domain/src/messaging/publisher/mod.rs
similarity index 60%
rename from backend/common/domain/src/messaging/publisher.rs
rename to backend/common/domain/src/messaging/publisher/mod.rs
index 26752fae57..6d50ad06f9 100644
--- a/backend/common/domain/src/messaging/publisher.rs
+++ b/backend/common/domain/src/messaging/publisher/mod.rs
@@ -1,9 +1,13 @@
+use std::fmt::Debug;
+
 use async_trait::async_trait;
+pub use message::Message;
 #[cfg(test)]
 use mockall::automock;
 use thiserror::Error;

-use super::{Destination, Message};
+pub mod composite;
+mod message;

 #[derive(Debug, Error)]
 pub enum Error {
@@ -18,10 +22,10 @@ pub enum Error {
 #[async_trait]
 #[cfg_attr(test, automock)]
 pub trait Publisher<M: Message + Sync + Send>: Send + Sync {
-	async fn publish(&self, destination: Destination, message: &M) -> Result<(), Error>;
-	async fn publish_many(&self, destination: Destination, messages: &[M]) -> Result<(), Error> {
+	async fn publish(&self, message: &M) -> Result<(), Error>;
+	async fn publish_many(&self, messages: &[M]) -> Result<(), Error> {
 		for message in messages {
-			self.publish(destination.clone(), message).await?;
+			self.publish(message).await?;
 		}
 		Ok(())
 	}
@@ -48,12 +52,8 @@ mod tests {

 	#[async_trait]
 	impl Publisher<TestMessage> for TestPublisher {
-		async fn publish(
-			&self,
-			destination: Destination,
-			message: &TestMessage,
-		) -> Result<(), Error> {
-			self.0.publish(destination, message).await
+		async fn publish(&self, message: &TestMessage) -> Result<(), Error> {
+			self.0.publish(message).await
 		}
 	}
 	impl Extractor for TestMessage {
@@ -65,36 +65,31 @@ mod tests {
 			Vec::default()
 		}
 	}
-	impl Message for TestMessage {}

 	#[rstest]
 	async fn publish_many_messages() {
-		let destination = Destination::Queue("test_queue".to_string());
 		let mut publisher = MockPublisher::<TestMessage>::new();

 		publisher
 			.expect_publish()
-			.with(eq(destination.clone()), eq(TestMessage::Msg1))
+			.with(eq(TestMessage::Msg1))
 			.once()
-			.returning(|_, _| async { Ok(()) }.boxed());
+			.returning(|_| async { Ok(()) }.boxed());

 		publisher
 			.expect_publish()
-			.with(eq(destination.clone()), eq(TestMessage::Msg2))
+			.with(eq(TestMessage::Msg2))
 			.once()
-			.returning(|_, _| async { Ok(()) }.boxed());
+			.returning(|_| async { Ok(()) }.boxed());

 		publisher
 			.expect_publish()
-			.with(eq(destination.clone()), eq(TestMessage::Msg3))
+			.with(eq(TestMessage::Msg3))
 			.once()
-			.returning(|_, _| async { Ok(()) }.boxed());
+			.returning(|_| async { Ok(()) }.boxed());

 		let result = TestPublisher(publisher)
-			.publish_many(
-				destination,
-				&[TestMessage::Msg1, TestMessage::Msg2, TestMessage::Msg3],
-			)
+			.publish_many(&[TestMessage::Msg1, TestMessage::Msg2, TestMessage::Msg3])
 			.await;
 		assert!(result.is_ok(), "{}", result.err().unwrap());
 	}
diff --git a/backend/common/domain/src/messaging/destination.rs b/backend/common/infrastructure/src/amqp/bus/destination.rs
similarity index 100%
rename from backend/common/domain/src/messaging/destination.rs
rename to backend/common/infrastructure/src/amqp/bus/destination.rs
diff --git a/backend/common/infrastructure/src/amqp/bus.rs b/backend/common/infrastructure/src/amqp/bus/mod.rs
similarity index 91%
rename from backend/common/infrastructure/src/amqp/bus.rs
rename to backend/common/infrastructure/src/amqp/bus/mod.rs
index f4d90eb5ba..cc53b01d17 100644
--- a/backend/common/infrastructure/src/amqp/bus.rs
+++ b/backend/common/infrastructure/src/amqp/bus/mod.rs
@@ -1,5 +1,6 @@
 use std::sync::{Arc, Weak};

+use domain::Message;
 use lapin::{
 	message::Delivery,
 	options::{BasicCancelOptions, ExchangeDeclareOptions, QueueDeclareOptions},
@@ -12,7 +13,12 @@ use tokio::sync::{Mutex, RwLock};
 use tokio_retry::{strategy::FixedInterval, Retry};
 use tokio_stream::StreamExt;

-use super::Config;
+use super::{Config, UniqueMessage};
+
+mod destination;
+mod publisher;
+mod subscriber;
+pub use destination::Destination;

 const DELIVERY_MODE_PERSISTENT: u8 = 2;

@@ -20,6 +26,8 @@ const DELIVERY_MODE_PERSISTENT: u8 = 2;
 pub enum Error {
 	#[error(transparent)]
 	Amqp(#[from] lapin::Error),
+	#[error(transparent)]
+	Serde(#[from] serde_json::Error),
 }

 pub struct Bus {
@@ -50,6 +58,13 @@ impl Bus {
 		})
 	}

+	pub fn as_publisher(self, destination: Destination) -> PublisherBus {
+		PublisherBus {
+			bus: self,
+			destination,
+		}
+	}
+
 	pub async fn with_queue(
 		self,
 		queue_name: String,
@@ -59,11 +74,11 @@ impl Bus {
 		ConsumableBus::new(self, queue_name).await
 	}

-	pub async fn publish(
+	pub async fn publish<M: Message>(
 		&self,
 		exchange_name: &str,
 		routing_key: &str,
-		data: &[u8],
+		message: UniqueMessage<M>,
 	) -> Result<Confirmation, Error> {
 		let confirmation = self
 			.channel
@@ -71,7 +86,7 @@ impl Bus {
 				exchange_name,
 				routing_key,
 				Default::default(),
-				data,
+				&serde_json::to_vec(&message)?,
 				BasicProperties::default().with_delivery_mode(DELIVERY_MODE_PERSISTENT),
 			)
 			.await?
@@ -156,6 +171,11 @@ impl ConsumableBus {
 	}
 }

+pub struct PublisherBus {
+	bus: Bus,
+	destination: Destination,
+}
+
 lazy_static! {
 	static ref CONNECTION: Mutex<Option<Weak<Connection>>> = Mutex::new(None);
 }
diff --git a/backend/common/infrastructure/src/amqp/bus/publisher.rs b/backend/common/infrastructure/src/amqp/bus/publisher.rs
new file mode 100644
index 0000000000..4ba431d3c2
--- /dev/null
+++ b/backend/common/infrastructure/src/amqp/bus/publisher.rs
@@ -0,0 +1,27 @@
+use anyhow::anyhow;
+use async_trait::async_trait;
+use domain::{Message, Publisher, PublisherError};
+
+use super::{Destination, PublisherBus};
+use crate::amqp::unique_message::Unique;
+
+#[async_trait]
+impl<M: Message + Send + Sync> Publisher<M> for PublisherBus {
+	async fn publish(&self, message: &M) -> Result<(), PublisherError> {
+		let (exchange_name, routing_key) = match self.destination.clone() {
+			Destination::Queue(name) => (String::new(), name),
+			Destination::Exchange(name) => (name, String::new()),
+		};
+
+		let confirmation = self
+			.bus
+			.publish(&exchange_name, &routing_key, message.clone().unique())
+			.await
+			.map_err(|e| PublisherError::Send(anyhow!(e)))?;
+
+		match confirmation.is_nack() {
+			true => Err(PublisherError::Nack),
+			false => Ok(()),
+		}
+	}
+}
diff --git a/backend/common/infrastructure/src/amqp/subscriber.rs b/backend/common/infrastructure/src/amqp/bus/subscriber.rs
similarity index 91%
rename from backend/common/infrastructure/src/amqp/subscriber.rs
rename to backend/common/infrastructure/src/amqp/bus/subscriber.rs
index 12db45a9c1..c3c2237939 100644
--- a/backend/common/infrastructure/src/amqp/subscriber.rs
+++ b/backend/common/infrastructure/src/amqp/bus/subscriber.rs
@@ -5,7 +5,10 @@ use async_trait::async_trait;
 use domain::{Message, Subscriber, SubscriberCallbackError, SubscriberError};
 use lapin::{message::Delivery, options::BasicNackOptions};
 use olog::{error, IntoField};
-use opentelemetry::{propagation::TextMapPropagator, sdk::propagation::TraceContextPropagator};
+use opentelemetry::{
+	propagation::{Extractor, TextMapPropagator},
+	sdk::propagation::TraceContextPropagator,
+};
 use serde_json::Error;
 use tracing::{instrument, Span};
 use tracing_opentelemetry::OpenTelemetrySpanExt;
@@ -13,7 +16,7 @@ use tracing_opentelemetry::OpenTelemetrySpanExt;
 use super::ConsumableBus;

 #[async_trait]
-impl<M: Message + Send + Sync> Subscriber<M> for ConsumableBus {
+impl<M: Message + Extractor + Send + Sync> Subscriber<M> for ConsumableBus {
 	async fn subscribe<C, F>(&self, callback: C) -> Result<(), SubscriberError>
 	where
 		C: Fn(M) -> F + Send + Sync,
@@ -53,7 +56,7 @@ impl ConsumableBus {
 		delivery: Delivery,
 	) -> Result<(), SubscriberError>
 	where
-		M: Message + Send + Sync,
+		M: Message + Send + Sync + Extractor,
 		C: Fn(M) -> F + Send + Sync,
 		F: Future<Output = Result<(), SubscriberCallbackError>> + Send,
 	{
diff --git a/backend/common/infrastructure/src/amqp/command/message.rs b/backend/common/infrastructure/src/amqp/command/message.rs
index 4b8e85ef6d..796cbee0a6 100644
--- a/backend/common/infrastructure/src/amqp/command/message.rs
+++ b/backend/common/infrastructure/src/amqp/command/message.rs
@@ -1,6 +1,6 @@
 use std::fmt::Debug;

-use domain::{CommandId, Message, MessagePayload};
+use domain::{CommandId, Message};
 use olog::opentelemetry::propagation::Extractor;
 use serde::{Deserialize, Serialize};

@@ -19,9 +19,7 @@ impl<P> Extractor for Decorator<P> {
 	}
 }

-impl<P: MessagePayload> Message for Decorator<P> {}
-
-impl<P: MessagePayload> Decorator<P> {
+impl<P: Message> Decorator<P> {
 	pub fn new(command_id: CommandId, payload: P) -> Self {
 		Self(UniqueMessage::new(payload).with_command(command_id))
 	}
diff --git a/backend/common/infrastructure/src/amqp/command/publisher.rs b/backend/common/infrastructure/src/amqp/command/publisher.rs
index 3ecc327eb4..072995e420 100644
--- a/backend/common/infrastructure/src/amqp/command/publisher.rs
+++ b/backend/common/infrastructure/src/amqp/command/publisher.rs
@@ -1,9 +1,7 @@
 use std::sync::Arc;

 use async_trait::async_trait;
-use domain::{
-	CommandAggregateId, CommandId, CommandRepository, Destination, Event, Publisher, PublisherError,
-};
+use domain::{CommandAggregateId, CommandId, CommandRepository, Event, Publisher, PublisherError};
 use olog::IntoField;

 use super::CommandMessage;
@@ -58,16 +56,12 @@ impl<P> Publisher<CommandMessage<Event>> for CommandPublisher<P>
 where
 	P: Publisher<UniqueMessage<Event>>,
 {
-	async fn publish(
-		&self,
-		destination: Destination,
-		message: &CommandMessage<Event>,
-	) -> Result<(), PublisherError> {
+	async fn publish(&self, message: &CommandMessage<Event>) -> Result<(), PublisherError> {
 		self.upsert_command(
 			&message.command_id(),
 			message.inner().payload().clone().into(),
 		)?;
-		self.publisher.publish(destination, message.inner()).await.map_err(|error| {
+		self.publisher.publish(message.inner()).await.map_err(|error| {
 			self.cancel_command(&message.command_id());
 			error
 		})
diff --git a/backend/common/infrastructure/src/amqp/mod.rs b/backend/common/infrastructure/src/amqp/mod.rs
index e05d8d26d4..f13486f68f 100644
--- a/backend/common/infrastructure/src/amqp/mod.rs
+++ b/backend/common/infrastructure/src/amqp/mod.rs
@@ -1,14 +1,11 @@
 mod bus;
-pub use bus::{Bus, ConsumableBus, Error as BusError};
+pub use bus::{Bus, ConsumableBus, Destination, Error as BusError};

 mod config;
 pub use config::Config;

-mod publisher;
-mod subscriber;
-
 mod unique_message;
-pub use unique_message::UniqueMessage;
+pub use unique_message::{Unique, UniqueMessage};

 mod command;
 pub use command::{
diff --git a/backend/common/infrastructure/src/amqp/publisher.rs b/backend/common/infrastructure/src/amqp/publisher.rs
deleted file mode 100644
index 9b9ebb8cbb..0000000000
--- a/backend/common/infrastructure/src/amqp/publisher.rs
+++ /dev/null
@@ -1,25 +0,0 @@
-use anyhow::anyhow;
-use async_trait::async_trait;
-use domain::{Destination, Message, Publisher, PublisherError};
-
-use super::Bus;
-
-#[async_trait]
-impl<M: Message + Send + Sync> Publisher<M> for Bus {
-	async fn publish(&self, destination: Destination, message: &M) -> Result<(), PublisherError> {
-		let (exchange_name, routing_key) = match destination {
-			Destination::Queue(name) => (String::new(), name),
-			Destination::Exchange(name) => (name, String::new()),
-		};
-
-		let confirmation = self
-			.publish(&exchange_name, &routing_key, &serde_json::to_vec(message)?)
-			.await
-			.map_err(|e| PublisherError::Send(anyhow!(e)))?;
-
-		match confirmation.is_nack() {
-			true => Err(PublisherError::Nack),
-			false => Ok(()),
-		}
-	}
-}
diff --git a/backend/common/infrastructure/src/amqp/unique_message.rs b/backend/common/infrastructure/src/amqp/unique_message.rs
index 46cf938055..e4742014db 100644
--- a/backend/common/infrastructure/src/amqp/unique_message.rs
+++ b/backend/common/infrastructure/src/amqp/unique_message.rs
@@ -5,7 +5,7 @@ use std::{

 use chrono::{NaiveDateTime, Utc};
 use derive_getters::Getters;
-use domain::{CommandId, Message, MessagePayload};
+use domain::CommandId;
 use olog::{
 	opentelemetry::{
 		propagation::{Extractor, TextMapPropagator},
@@ -38,8 +38,6 @@ impl<P> Extractor for UniqueMessage<P> {
 	}
 }

-impl<P: MessagePayload> Message for UniqueMessage<P> {}
-
 impl<P> UniqueMessage<P> {
 	pub fn new(payload: P) -> Self {
 		let mut trace_context = HashMap::new();
@@ -81,3 +79,16 @@ impl<P: Serialize> Display for UniqueMessage<P> {
 		Ok(())
 	}
 }
+
+pub trait Unique
+where
+	Self: Sized,
+{
+	fn unique(self) -> UniqueMessage<Self>;
+}
+
+impl<P> Unique for P {
+	fn unique(self) -> UniqueMessage<Self> {
+		UniqueMessage::new(self)
+	}
+}
diff --git a/backend/common/infrastructure/tests/amqp_subscriber_it.rs b/backend/common/infrastructure/tests/amqp_subscriber_it.rs
index 631d481aa9..f2ccf19559 100644
--- a/backend/common/infrastructure/tests/amqp_subscriber_it.rs
+++ b/backend/common/infrastructure/tests/amqp_subscriber_it.rs
@@ -6,8 +6,8 @@ use std::sync::{
 };

 use anyhow::anyhow;
-use domain::{Message, Subscriber, SubscriberCallbackError, SubscriberError};
-use infrastructure::amqp::{Bus, ConsumableBus};
+use domain::{Subscriber, SubscriberCallbackError, SubscriberError};
+use infrastructure::amqp::{Bus, ConsumableBus, Unique};
 use lapin::options::QueueDeclareOptions;
 use mockall::lazy_static;
 use opentelemetry::propagation::Extractor;
@@ -33,7 +33,6 @@ impl Extractor for TestMessage {
 		Vec::default()
 	}
 }
-impl Message for TestMessage {}

 async fn init(bus: Bus, queue_name: &'static str) -> ConsumableBus {
 	bus.with_queue(
@@ -50,16 +49,14 @@ async fn init(bus: Bus, queue_name: &'static str) -> ConsumableBus {
 }

 async fn publish_message(bus: &Bus, queue_name: &'static str, message: TestMessage) {
-	let confirmation = bus
-		.publish("", queue_name, &serde_json::to_vec(&message).unwrap())
-		.await
-		.unwrap();
+	let confirmation = bus.publish("", queue_name, message.unique()).await.unwrap();

 	assert!(!confirmation.is_nack());
 }

 async fn publish_badly_formatted_message(bus: &Bus, queue_name: &'static str) {
-	let confirmation = bus.publish("", queue_name, "bad-message".as_bytes()).await.unwrap();
+	let confirmation =
+		bus.publish("", queue_name, String::from("bad-message").unique()).await.unwrap();

 	assert!(!confirmation.is_nack());
 }
diff --git a/backend/common/testing/src/context/amqp.rs b/backend/common/testing/src/context/amqp.rs
index b24e7deb50..95de996683 100644
--- a/backend/common/testing/src/context/amqp.rs
+++ b/backend/common/testing/src/context/amqp.rs
@@ -1,8 +1,8 @@
 use std::{collections::HashMap, sync::Arc};

 use anyhow::{anyhow, Result};
-use domain::{Destination, Event, Publisher, Subscriber, SubscriberCallbackError};
-use infrastructure::amqp::{self, Bus, BusError, ConsumableBus, UniqueMessage};
+use domain::{Event, Publisher, Subscriber, SubscriberCallbackError};
+use infrastructure::amqp::{self, Bus, BusError, ConsumableBus, Destination};
 use lapin::options::QueueDeclareOptions;
 use serde_json::Value;
 use testcontainers::{
@@ -15,7 +15,7 @@ pub struct Context<'docker> {
 	pub config: amqp::Config,
 	pub listeners: HashMap<String, UnboundedReceiver<Value>>,
 	kill_channels: Vec<UnboundedSender<()>>,
-	publisher: Arc<dyn Publisher<UniqueMessage<Event>>>,
+	publisher: Arc<dyn Publisher<Event>>,
 	_container: Container<'docker, GenericImage>,
 }

@@ -74,7 +74,9 @@ impl<'docker> Context<'docker> {
 			_container: container,
 			config: config.clone(),
 			listeners,
-			publisher: Arc::new(Bus::new(config).await?),
+			publisher: Arc::new(
+				Bus::new(config).await?.as_publisher(Destination::queue("quote_sync")),
+			),
 			kill_channels,
 		})
 	}
@@ -91,8 +93,8 @@ impl<'docker> Context<'docker> {
 			.map(|value| serde_json::from_value(value).expect("Unable to deserialize message"))
 	}

-	pub async fn publish<E: Into<Event>>(&self, destination: Destination, event: E) -> Result<()> {
-		self.publisher.publish(destination, &UniqueMessage::new(event.into())).await?;
+	pub async fn publish<E: Into<Event>>(&self, event: E) -> Result<()> {
+		self.publisher.publish(&event.into()).await?;
 		Ok(())
 	}
 }
diff --git a/backend/common/testing/src/context/database.rs b/backend/common/testing/src/context/database.rs
index ed4817d836..013cc3f03a 100644
--- a/backend/common/testing/src/context/database.rs
+++ b/backend/common/testing/src/context/database.rs
@@ -1,3 +1,5 @@
+use std::sync::Arc;
+
 use anyhow::{anyhow, Result};
 use infrastructure::database;
 use testcontainers::{
@@ -11,7 +13,7 @@ static DATABASE: &str = "marketplace_db";
 pub struct Context<'docker> {
 	_container: Container<'docker, GenericImage>,
 	pub config: database::Config,
-	pub client: database::Client,
+	pub client: Arc<database::Client>,
 }

 impl<'docker> Context<'docker> {
@@ -34,7 +36,7 @@ impl<'docker> Context<'docker> {
 		Ok(Self {
 			_container: container,
 			config,
-			client,
+			client: Arc::new(client),
 		})
 	}
 }
diff --git a/backend/event-listeners/Procfile b/backend/event-listeners/Procfile
index 481dc780b0..7ea82d903a 100644
--- a/backend/event-listeners/Procfile
+++ b/backend/event-listeners/Procfile
@@ -1,4 +1,4 @@
 event-listeners: ./backend/target/release/listeners
-refresh: RUST_LOG=info ./backend/target/release/refresh
+refresh: RUST_LOG=info ./backend/target/release/refresh_deprecated
 github-indexer: ./backend/target/release/github-indexer
 web: ROCKET_PORT=$PORT ./backend/target/release/event-listeners
diff --git a/backend/event-listeners/src/bin/refresh-deprecated/app.yaml b/backend/event-listeners/src/bin/refresh-deprecated/app.yaml
new file mode 100644
index 0000000000..42fa4c740f
--- /dev/null
+++ b/backend/event-listeners/src/bin/refresh-deprecated/app.yaml
@@ -0,0 +1,28 @@
+default:
+  github:
+    base_url: $GITHUB_BASE_URL
+    personal_access_tokens: $GITHUB_PAT
+    max_calls_per_request: $GITHUB_MAX_CALLS_PER_REQUEST
+  tracer:
+    json: false
+    ansi: true
+    location: false
+  amqp:
+    connection_retry_interval_ms: 6000
+    connection_retry_count: 1
+  http:
+    api_keys: []
+
+local:
+  database:
+    url: postgres://postgres:postgres@localhost/marketplace_db
+    pool_max_size: 3
+  amqp:
+    url: "amqp://127.0.0.1:5672/%2f"
+
+production:
+  database:
+    url: $DATABASE_URL
+    pool_max_size: 3
+  amqp:
+    url: $CLOUDAMQP_URL
diff --git a/backend/event-listeners/src/bin/refresh/cli.rs b/backend/event-listeners/src/bin/refresh-deprecated/cli.rs
similarity index 100%
rename from backend/event-listeners/src/bin/refresh/cli.rs
rename to backend/event-listeners/src/bin/refresh-deprecated/cli.rs
diff --git a/backend/event-listeners/src/bin/refresh-deprecated/main.rs b/backend/event-listeners/src/bin/refresh-deprecated/main.rs
new file mode 100644
index 0000000000..d9d4ca5b3f
--- /dev/null
+++ b/backend/event-listeners/src/bin/refresh-deprecated/main.rs
@@ -0,0 +1,36 @@
+use ::infrastructure::config;
+use anyhow::{anyhow, Result};
+use clap::Parser;
+use dotenv::dotenv;
+use event_listeners::Config;
+use futures::future::try_join_all;
+use infrastructure::tracing::Tracer;
+
+mod refresher;
+use refresher::Registry;
+
+mod cli;
+
+#[tokio::main]
+async fn main() -> Result<()> {
+	dotenv().ok();
+	let config: Config = config::load("backend/event-listeners/src/bin/refresh/app.yaml")?;
+	let _tracer = Tracer::init(config.tracer, "refresh")?;
+
+	let registry = Registry::new();
+
+	let (aggregate_name, aggregate_ids, all_ids) = cli::Args::parse().dissolve();
+
+	let refresher = registry.get(&aggregate_name).ok_or_else(|| anyhow!("Aggregate not found"))?;
+
+	let aggregate_ids = match all_ids {
+		true => refresher.all_ids()?,
+		false => aggregate_ids,
+	};
+
+	let handles = aggregate_ids.iter().map(|id| refresher.refresh(id));
+
+	try_join_all(handles).await?;
+
+	Ok(())
+}
diff --git a/backend/event-listeners/src/bin/refresh/refresher/mod.rs b/backend/event-listeners/src/bin/refresh-deprecated/refresher/mod.rs
similarity index 77%
rename from backend/event-listeners/src/bin/refresh/refresher/mod.rs
rename to backend/event-listeners/src/bin/refresh-deprecated/refresher/mod.rs
index cf33e03e8b..086257ea3a 100644
--- a/backend/event-listeners/src/bin/refresh/refresher/mod.rs
+++ b/backend/event-listeners/src/bin/refresh-deprecated/refresher/mod.rs
@@ -3,23 +3,17 @@ use std::{str::FromStr, sync::Arc};
 use anyhow::{anyhow, Result};
 use async_trait::async_trait;
 use derive_more::Constructor;
-use domain::{Event, EventSourcable, EventStore, Identified};
-
-mod registry;
-use event_listeners::listeners::EventListener;
+use domain::{Event, EventListener, EventSourcable, EventStore, Identified};
 use itertools::Itertools;
 use olog::info;
 pub use registry::{Registrable, Registry};

-pub mod application;
-pub mod budget;
-pub mod payment;
-pub mod project;
+mod registry;

 #[derive(Constructor)]
 pub struct Refresher<A: EventSourcable> {
 	event_store: Arc<dyn EventStore<A>>,
-	projectors: Vec<Arc<dyn EventListener<Event>>>,
+	projector: Arc<dyn EventListener<Event>>,
 }

 #[async_trait]
@@ -60,10 +54,7 @@ where
 		}

 		for event in events {
-			let event: Event = event.into();
-			for projector in &self.projectors {
-				projector.on_event(event.clone()).await?;
-			}
+			self.projector.on_event(event.into()).await?;
 		}
 		Ok(())
 	}
diff --git a/backend/event-listeners/src/bin/refresh-deprecated/refresher/registry.rs b/backend/event-listeners/src/bin/refresh-deprecated/refresher/registry.rs
new file mode 100644
index 0000000000..d47e998921
--- /dev/null
+++ b/backend/event-listeners/src/bin/refresh-deprecated/refresher/registry.rs
@@ -0,0 +1,21 @@
+use std::{collections::HashMap, sync::Arc};
+
+use anyhow::{anyhow, Result};
+
+use super::Refreshable;
+
+pub type Registry = HashMap<String, Arc<dyn Refreshable>>;
+
+pub trait Registrable {
+	fn register(self, registry: &mut Registry, key: &'static str) -> Result<()>;
+}
+
+impl<R: Refreshable + 'static> Registrable for R {
+	fn register(self, registry: &mut Registry, key: &'static str) -> Result<()> {
+		if registry.insert(key.to_string(), Arc::new(self)).is_some() {
+			return Err(anyhow!("Refresher already exists"))?;
+		}
+
+		Ok(())
+	}
+}
diff --git a/backend/event-listeners/src/bin/refresh/refresher/application.rs b/backend/event-listeners/src/bin/refresh/refresher/application.rs
deleted file mode 100644
index 3515e85eb9..0000000000
--- a/backend/event-listeners/src/bin/refresh/refresher/application.rs
+++ /dev/null
@@ -1,13 +0,0 @@
-use std::sync::Arc;
-
-use domain::Application;
-use event_listeners::listeners::*;
-use infrastructure::database;
-
-use super::{Refreshable, Refresher};
-
-pub fn create(database: Arc<database::Client>) -> impl Refreshable {
-	let application_projector = application::Projector::new(database.clone());
-
-	Refresher::<Application>::new(database, vec![Arc::new(application_projector)])
-}
diff --git a/backend/event-listeners/src/bin/refresh/refresher/budget.rs b/backend/event-listeners/src/bin/refresh/refresher/budget.rs
deleted file mode 100644
index 9b650e859a..0000000000
--- a/backend/event-listeners/src/bin/refresh/refresher/budget.rs
+++ /dev/null
@@ -1,12 +0,0 @@
-use std::sync::Arc;
-
-use domain::Budget;
-use event_listeners::listeners::*;
-use infrastructure::database;
-
-use super::{Refreshable, Refresher};
-
-pub fn create(database: Arc<database::Client>) -> impl Refreshable {
-	let budget_projector = budget::Projector::new(database.clone());
-	Refresher::<Budget>::new(database, vec![Arc::new(budget_projector)])
-}
diff --git a/backend/event-listeners/src/bin/refresh/refresher/payment.rs b/backend/event-listeners/src/bin/refresh/refresher/payment.rs
deleted file mode 100644
index d46176d97a..0000000000
--- a/backend/event-listeners/src/bin/refresh/refresher/payment.rs
+++ /dev/null
@@ -1,20 +0,0 @@
-use std::sync::Arc;
-
-use domain::Payment;
-use event_listeners::listeners::*;
-use infrastructure::database;
-
-use super::{Refreshable, Refresher};
-
-pub fn create(database: Arc<database::Client>) -> impl Refreshable {
-	let payment_projector = payment::Projector::new(
-		database.clone(),
-		database.clone(),
-		database.clone(),
-		database.clone(),
-		database.clone(),
-		database.clone(),
-	);
-
-	Refresher::<Payment>::new(database, vec![Arc::new(payment_projector)])
-}
diff --git a/backend/event-listeners/src/bin/refresh/refresher/project.rs b/backend/event-listeners/src/bin/refresh/refresher/project.rs
deleted file mode 100644
index a83b5d144d..0000000000
--- a/backend/event-listeners/src/bin/refresh/refresher/project.rs
+++ /dev/null
@@ -1,21 +0,0 @@
-use std::sync::Arc;
-
-use domain::Project;
-use event_listeners::listeners::*;
-use infrastructure::database;
-
-use super::{Refreshable, Refresher};
-
-pub fn create(database: Arc<database::Client>) -> impl Refreshable {
-	let project_projector = project::Projector::new(
-		database.clone(),
-		database.clone(),
-		database.clone(),
-		database.clone(),
-		database.clone(),
-		database.clone(),
-		database.clone(),
-	);
-
-	Refresher::<Project>::new(database, vec![Arc::new(project_projector)])
-}
diff --git a/backend/event-listeners/src/listeners/application.rs b/backend/event-listeners/src/listeners/application.rs
deleted file mode 100644
index d7c23260f9..0000000000
--- a/backend/event-listeners/src/listeners/application.rs
+++ /dev/null
@@ -1,42 +0,0 @@
-use std::sync::Arc;
-
-use anyhow::Result;
-use async_trait::async_trait;
-use derive_new::new;
-use domain::{ApplicationEvent, Event, SubscriberCallbackError};
-use infrastructure::database::Repository;
-use tracing::instrument;
-
-use super::EventListener;
-use crate::models::*;
-
-#[derive(new)]
-pub struct Projector {
-	applications_repository: Arc<dyn Repository<Application>>,
-}
-
-#[async_trait]
-impl EventListener<Event> for Projector {
-	#[instrument(name = "project_projection", skip(self))]
-	async fn on_event(&self, event: Event) -> Result<(), SubscriberCallbackError> {
-		if let Event::Application(event) = event {
-			match event {
-				ApplicationEvent::Received {
-					id,
-					project_id,
-					applicant_id,
-					received_at,
-				} => {
-					self.applications_repository.try_insert(Application {
-						id,
-						received_at,
-						project_id,
-						applicant_id,
-					})?;
-				},
-			}
-		}
-
-		Ok(())
-	}
-}
diff --git a/backend/event-listeners/src/listeners/budget.rs b/backend/event-listeners/src/listeners/budget.rs
deleted file mode 100644
index ac15cb5df8..0000000000
--- a/backend/event-listeners/src/listeners/budget.rs
+++ /dev/null
@@ -1,48 +0,0 @@
-use std::sync::Arc;
-
-use anyhow::Result;
-use async_trait::async_trait;
-use derive_more::Constructor;
-use domain::{BudgetEvent, Event, SubscriberCallbackError};
-use infrastructure::database::Repository;
-use rust_decimal::Decimal;
-use tracing::instrument;
-
-use super::EventListener;
-use crate::models::*;
-
-#[derive(Constructor)]
-pub struct Projector {
-	budget_repository: Arc<dyn Repository<Budget>>,
-}
-
-#[async_trait]
-impl EventListener<Event> for Projector {
-	#[instrument(name = "budget_projection", skip(self))]
-	async fn on_event(&self, event: Event) -> Result<(), SubscriberCallbackError> {
-		if let Event::Budget(event) = event {
-			match event {
-				BudgetEvent::Created { id, currency } => {
-					self.budget_repository.upsert(Budget {
-						id,
-						initial_amount: Decimal::ZERO,
-						remaining_amount: Decimal::ZERO,
-						currency: currency.try_into()?,
-					})?;
-				},
-				BudgetEvent::Allocated { id, amount, .. } => {
-					let mut budget = self.budget_repository.find_by_id(id)?;
-					budget.remaining_amount += amount;
-					budget.initial_amount += amount;
-					self.budget_repository.update(budget)?;
-				},
-				BudgetEvent::Spent { id, amount } => {
-					let mut budget = self.budget_repository.find_by_id(id)?;
-					budget.remaining_amount -= amount;
-					self.budget_repository.update(budget)?;
-				},
-			}
-		}
-		Ok(())
-	}
-}
diff --git a/backend/event-listeners/src/listeners/logger.rs b/backend/event-listeners/src/listeners/logger.rs
index b812bb4043..53a74bb85a 100644
--- a/backend/event-listeners/src/listeners/logger.rs
+++ b/backend/event-listeners/src/listeners/logger.rs
@@ -1,11 +1,9 @@
 use anyhow::Result;
 use async_trait::async_trait;
-use domain::SubscriberCallbackError;
+use domain::{EventListener, SubscriberCallbackError};
 use olog::info;
 use serde_json::Value;

-use super::EventListener;
-
 pub struct Logger;

 #[async_trait]
diff --git a/backend/event-listeners/src/listeners/mod.rs b/backend/event-listeners/src/listeners/mod.rs
index 7232e21b78..52b939877c 100644
--- a/backend/event-listeners/src/listeners/mod.rs
+++ b/backend/event-listeners/src/listeners/mod.rs
@@ -1,16 +1,11 @@
-pub mod application;
-pub mod budget;
 pub mod logger;
-pub mod payment;
-pub mod project;
 pub mod quote_syncer;
 pub mod webhook;

 use std::sync::Arc;

 use anyhow::Result;
-use async_trait::async_trait;
-use domain::{currencies, LogErr, MessagePayload, Subscriber, SubscriberCallbackError};
+use domain::{currencies, EventListener, LogErr, Message, Subscriber, SubscriberCallbackError};
 use infrastructure::{
 	amqp::{CommandSubscriberDecorator, UniqueMessage},
 	coinmarketcap, database, event_bus,
@@ -23,8 +18,6 @@ use webhook::EventWebHook;
 use self::logger::Logger;
 use crate::Config;

-pub const GITHUB_EVENTS_EXCHANGE: &str = "github-events";
-
 pub async fn bootstrap(config: Config) -> Result<Vec<JoinHandle<()>>> {
 	let reqwest = reqwest::Client::new();
 	let database = Arc::new(database::Client::new(database::init_pool(
@@ -38,11 +31,6 @@ pub async fn bootstrap(config: Config) -> Result<Vec<JoinHandle<()>>> {
 	spawn_all(config, reqwest, database, coinmarketcap).await
 }

-#[async_trait]
-pub trait EventListener<E>: Send + Sync {
-	async fn on_event(&self, event: E) -> Result<(), SubscriberCallbackError>;
-}
-
 pub async fn spawn_all(
 	config: Config,
 	reqwest: reqwest::Client,
@@ -51,56 +39,11 @@ pub async fn spawn_all(
 ) -> Result<Vec<JoinHandle<()>>> {
 	let mut handles = vec![
 		Logger.spawn(event_bus::event_consumer(config.amqp.clone(), "logger").await?),
-		project::Projector::new(
-			database.clone(),
-			database.clone(),
-			database.clone(),
-			database.clone(),
-			database.clone(),
-			database.clone(),
-			database.clone(),
-		)
-		.spawn(
-			event_bus::event_consumer(config.amqp.clone(), "projects")
-				.await?
-				.into_command_subscriber(database.clone()),
-		),
-		budget::Projector::new(database.clone()).spawn(
-			event_bus::event_consumer(config.amqp.clone(), "budgets")
-				.await?
-				.into_command_subscriber(database.clone()),
-		),
-		application::Projector::new(database.clone()).spawn(
-			event_bus::event_consumer(config.amqp.clone(), "applications")
-				.await?
-				.into_command_subscriber(database.clone()),
-		),
-		payment::Projector::new(
-			database.clone(),
-			database.clone(),
-			database.clone(),
-			database.clone(),
-			database.clone(),
-			database.clone(),
-		)
-		.spawn(
-			event_bus::event_consumer(config.amqp.clone(), "payments")
-				.await?
-				.into_command_subscriber(database.clone()),
-		),
 		quote_syncer::Projector::new(database.clone(), coinmarketcap).spawn(
 			event_bus::event_consumer(config.amqp.clone(), "quote_sync")
 				.await?
 				.into_command_subscriber(database.clone()),
 		),
-		Logger.spawn(
-			event_bus::consumer_with_exchange(
-				config.amqp.clone(),
-				GITHUB_EVENTS_EXCHANGE,
-				"logger",
-			)
-			.await?,
-		),
 	];

 	for (index, target) in webhook_targets().into_iter().enumerate() {
@@ -115,13 +58,12 @@ pub async fn spawn_all(
 	Ok(handles)
 }

-pub trait Spawnable<E: MessagePayload + Send + Sync, S: Subscriber<UniqueMessage<E>> + Send + Sync>
-{
+pub trait Spawnable<E: Message + Send + Sync, S: Subscriber<UniqueMessage<E>> + Send + Sync> {
 	fn spawn(self, bus: S) -> JoinHandle<()>;
 }

 impl<
-	E: MessagePayload + Send + Sync,
+	E: Message + Send + Sync,
 	S: Subscriber<UniqueMessage<E>> + Send + Sync + 'static,
 	EL: EventListener<E> + 'static,
 > Spawnable<E, S> for EL
diff --git a/backend/event-listeners/src/listeners/payment.rs b/backend/event-listeners/src/listeners/payment.rs
deleted file mode 100644
index 719eb82cf6..0000000000
--- a/backend/event-listeners/src/listeners/payment.rs
+++ /dev/null
@@ -1,123 +0,0 @@
-use std::{convert::TryFrom, sync::Arc};
-
-use anyhow::Result;
-use async_trait::async_trait;
-use derive_more::Constructor;
-use domain::{Event, PaymentEvent, PaymentWorkItem, SubscriberCallbackError};
-use infrastructure::database::Repository;
-use tracing::instrument;
-
-use super::EventListener;
-use crate::models::*;
-
-#[derive(Constructor)]
-pub struct Projector {
-	payment_request_repository: Arc<dyn Repository<PaymentRequest>>,
-	payment_repository: Arc<dyn Repository<Payment>>,
-	work_item_repository: Arc<dyn WorkItemRepository>,
-	github_repo_index_repository: Arc<dyn GithubRepoIndexRepository>,
-	github_user_index_repository: Arc<dyn GithubUserIndexRepository>,
-	projects_rewarded_users_repository: Arc<dyn ProjectsRewardedUserRepository>,
-}
-
-#[async_trait]
-impl EventListener<Event> for Projector {
-	#[instrument(name = "budget_projection", skip(self))]
-	async fn on_event(&self, event: Event) -> Result<(), SubscriberCallbackError> {
-		if let Event::Payment(event) = event {
-			match event {
-				PaymentEvent::Requested {
-					id: payment_id,
-					project_id,
-					requestor_id,
-					recipient_id,
-					amount,
-					reason,
-					duration_worked,
-					requested_at,
-				} => {
-					self.payment_request_repository.upsert(PaymentRequest {
-						id: payment_id,
-						project_id,
-						requestor_id,
-						recipient_id,
-						amount: *amount.amount(),
-						currency: amount.currency().try_into()?,
-						requested_at,
-						invoice_received_at: None,
-						hours_worked: i32::try_from(duration_worked.num_hours()).unwrap_or(0),
-					})?;
-
-					reason.work_items.into_iter().try_for_each(
-						|work_item| -> Result<(), SubscriberCallbackError> {
-							let repo_id = match work_item {
-								PaymentWorkItem::Issue { repo_id, .. }
-								| PaymentWorkItem::CodeReview { repo_id, .. }
-								| PaymentWorkItem::PullRequest { repo_id, .. } => repo_id,
-							};
-
-							self.work_item_repository.try_insert(
-								(project_id, payment_id, recipient_id, work_item).into(),
-							)?;
-
-							self.github_repo_index_repository.start_indexing(repo_id)?;
-							Ok(())
-						},
-					)?;
-
-					self.github_user_index_repository.try_insert(GithubUserIndex {
-						user_id: recipient_id,
-						..Default::default()
-					})?;
-
-					self.projects_rewarded_users_repository
-						.increase_user_reward_count_for_project(&project_id, &recipient_id)?;
-				},
-				PaymentEvent::Cancelled { id: payment_id } => {
-					let payment_request = self.payment_request_repository.find_by_id(payment_id)?;
-					self.payment_request_repository.delete(payment_id)?;
-					self.work_item_repository.delete_by_payment_id(payment_id)?;
-
-					self.projects_rewarded_users_repository
-						.decrease_user_reward_count_for_project(
-							&payment_request.project_id,
-							&payment_request.recipient_id,
-						)?;
-				},
-				PaymentEvent::Processed {
-					id: payment_id,
-					receipt_id,
-					amount,
-					receipt,
-					processed_at,
-				} => {
-					self.payment_repository.upsert(Payment {
-						id: receipt_id,
-						amount: *amount.amount(),
-						currency_code: amount.currency().to_string(),
-						receipt: serde_json::to_value(receipt)
-							.map_err(|e| SubscriberCallbackError::Discard(e.into()))?,
-						request_id: payment_id,
-						processed_at,
-					})?;
-				},
-				PaymentEvent::InvoiceReceived {
-					id: payment_id,
-					received_at,
-				} => {
-					let mut payment_request =
-						self.payment_request_repository.find_by_id(payment_id)?;
-					payment_request.invoice_received_at = Some(received_at);
-					self.payment_request_repository.update(payment_request)?;
-				},
-				PaymentEvent::InvoiceRejected { id: payment_id } => {
-					let mut payment_request =
-						self.payment_request_repository.find_by_id(payment_id)?;
-					payment_request.invoice_received_at = None;
-					self.payment_request_repository.update(payment_request)?;
-				},
-			}
-		}
-		Ok(())
-	}
-}
diff --git a/backend/event-listeners/src/listeners/project.rs b/backend/event-listeners/src/listeners/project.rs
deleted file mode 100644
index 378e792621..0000000000
--- a/backend/event-listeners/src/listeners/project.rs
+++ /dev/null
@@ -1,83 +0,0 @@
-use std::sync::Arc;
-
-use anyhow::Result;
-use async_trait::async_trait;
-use derive_new::new;
-use domain::{Event, ProjectEvent, SubscriberCallbackError};
-use infrastructure::database::ImmutableRepository;
-use tracing::instrument;
-
-use super::EventListener;
-use crate::models::*;
-
-#[derive(new)]
-pub struct Projector {
-	project_repository: Arc<dyn ImmutableRepository<Project>>,
-	project_lead_repository: Arc<dyn ImmutableRepository<ProjectLead>>,
-	project_github_repos_repository: Arc<dyn ImmutableRepository<ProjectGithubRepo>>,
-	github_repo_index_repository: Arc<dyn GithubRepoIndexRepository>,
-	projects_contributors_repository: Arc<dyn ProjectsContributorRepository>,
-	projects_pending_contributors_repository: Arc<dyn ProjectsPendingContributorRepository>,
-	project_budgets_repository: Arc<dyn ImmutableRepository<ProjectsBudget>>,
-}
-
-#[async_trait]
-impl EventListener<Event> for Projector {
-	#[instrument(name = "project_projection", skip(self))]
-	async fn on_event(&self, event: Event) -> Result<(), SubscriberCallbackError> {
-		if let Event::Project(event) = event {
-			match event {
-				ProjectEvent::Created { id } => {
-					self.project_repository.try_insert(Project { id })?;
-				},
-				ProjectEvent::LeaderAssigned {
-					id: project_id,
-					leader_id,
-					assigned_at,
-				} => {
-					self.project_lead_repository.try_insert(ProjectLead {
-						project_id,
-						user_id: leader_id,
-						assigned_at,
-					})?;
-				},
-				ProjectEvent::LeaderUnassigned { id, leader_id } => {
-					self.project_lead_repository.delete((id, leader_id))?;
-				},
-				ProjectEvent::BudgetLinked { id, budget_id, .. } => {
-					self.project_budgets_repository.try_insert(ProjectsBudget {
-						project_id: id,
-						budget_id,
-					})?;
-				},
-				ProjectEvent::GithubRepoLinked {
-					id: project_id,
-					github_repo_id,
-				} => {
-					self.project_github_repos_repository.try_insert(ProjectGithubRepo {
-						project_id,
-						github_repo_id,
-					})?;
-					self.github_repo_index_repository.start_indexing(github_repo_id)?;
-					self.projects_contributors_repository
-						.refresh_project_contributor_list(&project_id)?;
-					self.projects_pending_contributors_repository
-						.refresh_project_pending_contributor_list(&project_id)?;
-				},
-				ProjectEvent::GithubRepoUnlinked {
-					id: project_id,
-					github_repo_id,
-				} => {
-					self.project_github_repos_repository.delete((project_id, github_repo_id))?;
-					self.projects_contributors_repository
-						.refresh_project_contributor_list(&project_id)?;
-					self.projects_pending_contributors_repository
-						.refresh_project_pending_contributor_list(&project_id)?;
-				},
-				ProjectEvent::Applied { .. } => (),
-			}
-		}
-
-		Ok(())
-	}
-}
diff --git a/backend/event-listeners/src/listeners/webhook/mod.rs b/backend/event-listeners/src/listeners/webhook/mod.rs
index fdef4ac359..16c3831da1 100644
--- a/backend/event-listeners/src/listeners/webhook/mod.rs
+++ b/backend/event-listeners/src/listeners/webhook/mod.rs
@@ -7,10 +7,9 @@ use tracing::instrument;
 use url::Url;

 mod event;
+use domain::EventListener;
 use event::Event as WebHookEvent;

-use super::EventListener;
-
 #[derive(new)]
 pub struct EventWebHook {
 	client: reqwest::Client,
diff --git a/backend/event-listeners/src/models/mod.rs b/backend/event-listeners/src/models/mod.rs
index af377cb854..ac8f7b389d 100644
--- a/backend/event-listeners/src/models/mod.rs
+++ b/backend/event-listeners/src/models/mod.rs
@@ -1,5 +1,3 @@
-mod applications;
-mod budgets;
 mod contributions;
 mod crypto_usd_quotes;
 mod github_issues;
@@ -9,20 +7,11 @@ mod github_repo_indexes;
 mod github_repos;
 mod github_user_indexes;
 mod github_users;
-mod payment_requests;
-mod payments;
 mod project_github_repos;
-mod project_leads;
-mod projects;
-mod projects_budgets;
 mod projects_contributors;
 mod projects_pending_contributors;
-mod projects_rewarded_users;
 mod technologies;
-mod work_items;

-pub use applications::Application;
-pub use budgets::Budget;
 pub use contributions::{Contribution, Repository as ContributionsRepository};
 pub use crypto_usd_quotes::CryptoUsdQuote;
 use diesel::PgConnection;
@@ -38,21 +27,12 @@ pub use github_repos::GithubRepo;
 pub use github_user_indexes::{GithubUserIndex, Repository as GithubUserIndexRepository};
 pub use github_users::GithubUser;
 use infrastructure::database::{self, ImmutableModel, ImmutableRepository};
-pub use payment_requests::PaymentRequest;
-pub use payments::Payment;
 pub use project_github_repos::{ProjectGithubRepo, Repository as ProjectGithubRepoRepository};
-pub use project_leads::ProjectLead;
-pub use projects::Project;
-pub use projects_budgets::ProjectsBudget;
 pub use projects_contributors::{ProjectsContributor, Repository as ProjectsContributorRepository};
 pub use projects_pending_contributors::{
 	ProjectsPendingContributor, Repository as ProjectsPendingContributorRepository,
 };
-pub use projects_rewarded_users::{
-	ProjectsRewardedUser, Repository as ProjectsRewardedUserRepository,
-};
 pub use technologies::Technology;
-pub use work_items::{Repository as WorkItemRepository, WorkItem};

 pub trait IdentifiableRepository<M, Id>: Send + Sync {
 	fn exists(&self, id: Id) -> database::Result<bool>;
diff --git a/backend/event-listeners/tests/quote_sync_upon_budget_creation_it.rs b/backend/event-listeners/tests/quote_sync_upon_budget_creation_it.rs
index 0be44b6f92..0599940ec4 100644
--- a/backend/event-listeners/tests/quote_sync_upon_budget_creation_it.rs
+++ b/backend/event-listeners/tests/quote_sync_upon_budget_creation_it.rs
@@ -1,6 +1,6 @@
 use anyhow::Result;
 use chrono::Utc;
-use domain::{currencies, BudgetId, Destination};
+use domain::{currencies, BudgetId};
 use event_listeners::models::CryptoUsdQuote;
 use fixtures::*;
 use infrastructure::database::{enums::Currency, ImmutableRepository};
@@ -40,13 +40,10 @@ impl<'a> Test<'a> {
 		// When
 		self.context
 			.amqp
-			.publish(
-				Destination::queue("quote_sync"),
-				domain::BudgetEvent::Created {
-					id: BudgetId::new(),
-					currency: currencies::ETH,
-				},
-			)
+			.publish(domain::BudgetEvent::Created {
+				id: BudgetId::new(),
+				currency: currencies::ETH,
+			})
 			.await?;

 		// Then
diff --git a/backend/event-store/src/main.rs b/backend/event-store/src/main.rs
index 3a1f8fe681..b37c7e9680 100644
--- a/backend/event-store/src/main.rs
+++ b/backend/event-store/src/main.rs
@@ -2,11 +2,9 @@ use std::sync::Arc;

 use ::olog::info;
 use anyhow::Result;
-use backend_domain::{
-	Destination, Event, Identified, Publisher, Subscriber, SubscriberCallbackError,
-};
+use backend_domain::{Event, Identified, Publisher, Subscriber, SubscriberCallbackError};
 use backend_infrastructure::{
-	amqp::{self, Bus, UniqueMessage},
+	amqp::{self, Bus, Destination, UniqueMessage},
 	config,
 	database::{self, init_pool, Client as DatabaseClient},
 	event_bus::EXCHANGE_NAME,
@@ -31,7 +29,8 @@ async fn main() -> Result<()> {
 	let _tracer = Tracer::init(config.tracer, "event_store")?;

 	let inbound_event_bus = bus::consumer(config.amqp.clone()).await?;
-	let outbound_event_bus = Arc::new(Bus::new(config.amqp).await?);
+	let outbound_event_bus =
+		Arc::new(Bus::new(config.amqp).await?.as_publisher(Destination::exchange(EXCHANGE_NAME)));
 	let database = Arc::new(DatabaseClient::new(init_pool(config.database)?));

 	inbound_event_bus
@@ -67,7 +66,7 @@ async fn publish(
 	let message = message.copy();

 	publisher
-		.publish(Destination::exchange(EXCHANGE_NAME), &message)
+		.publish(&message)
 		.await
 		.map_err(|e| SubscriberCallbackError::Fatal(e.into()))?;
 	Ok(())